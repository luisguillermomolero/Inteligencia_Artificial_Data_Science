{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b45fb629",
   "metadata": {},
   "source": [
    "# Clase 2 ‚Äî Redes Neuronales Convolucionales (CNNs)\n",
    "\n",
    "---\n",
    "\n",
    "### 1. **Concepto General**\n",
    "\n",
    "Una **Red Neuronal Convolucional (CNN, por sus siglas en ingl√©s)** \n",
    "    \n",
    "Es un tipo de red neuronal profunda dise√±ada especialmente para **procesar datos con estructura en forma de cuadr√≠cula**, como **im√°genes**, **videos**, o incluso **series temporales multivariadas** (por ejemplo, se√±ales de sensores).\n",
    "\n",
    "Las CNN son una evoluci√≥n de las redes neuronales artificiales tradicionales (ANN), pero con una **arquitectura optimizada para la percepci√≥n visual**, inspirada en el **corte visual del cerebro humano**, donde existen neuronas sensibles a patrones locales (bordes, colores, texturas).\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Estructura General de una CNN**\n",
    "\n",
    "Una CNN est√° compuesta por **una secuencia de capas** que transforman gradualmente la imagen de entrada en una representaci√≥n abstracta que permite clasificarla o analizarla.\n",
    "Las capas principales son:\n",
    "\n",
    "#### a) **Capa de Convoluci√≥n (Convolutional Layer)**\n",
    "\n",
    "* Es el **n√∫cleo fundamental** de la CNN.\n",
    "* Realiza una **operaci√≥n de convoluci√≥n** entre la imagen de entrada y un conjunto de **filtros (kernels)**.\n",
    "* Cada filtro es una peque√±a matriz de pesos que **detecta una caracter√≠stica local**, como bordes, esquinas o texturas.\n",
    "* Al desplazarse (o ‚Äúconvolucionar‚Äù) sobre la imagen, genera un **mapa de caracter√≠sticas (feature map)**.\n",
    "\n",
    "**Intuici√≥n:**\n",
    "Cada filtro aprende a detectar un patr√≥n espec√≠fico. En capas iniciales: bordes y colores. En capas profundas: formas, texturas y finalmente objetos completos.\n",
    "\n",
    "---\n",
    "\n",
    "#### b) **Capa de Activaci√≥n (Activation Layer)**\n",
    "\n",
    "Despu√©s de la convoluci√≥n, se aplica una funci√≥n no lineal ‚Äît√≠picamente **ReLU (Rectified Linear Unit)**‚Äî para introducir **no linealidad** en el modelo y evitar que se comporte como una simple combinaci√≥n lineal.\n",
    "\n",
    "Esto ayuda a que la red aprenda representaciones m√°s complejas.\n",
    "\n",
    "---\n",
    "\n",
    "#### c) **Capa de Submuestreo o Pooling (Pooling Layer)**\n",
    "\n",
    "Reduce la **dimensi√≥n espacial** de los mapas de caracter√≠sticas, conservando la informaci√≥n m√°s importante.\n",
    "\n",
    "* **Tipos comunes:**\n",
    "\n",
    "  * *Max Pooling:* toma el valor m√°ximo de una regi√≥n.\n",
    "  * *Average Pooling:* calcula el promedio de una regi√≥n.\n",
    "\n",
    "‚úÖ **Ventajas:**\n",
    "\n",
    "* Reduce el n√∫mero de par√°metros (menos c√≥mputo).\n",
    "* Aumenta la **invariancia a traslaciones** (si el objeto se mueve un poco, sigue siendo reconocido).\n",
    "\n",
    "---\n",
    "\n",
    "#### d) **Capas Completamente Conectadas (Fully Connected Layers)**\n",
    "\n",
    "Estas son similares a las de una red neuronal tradicional.\n",
    "\n",
    "* Reciben los mapas de caracter√≠sticas aplanados (flattened).\n",
    "* Combinan toda la informaci√≥n extra√≠da para realizar la **clasificaci√≥n final**.\n",
    "\n",
    "---\n",
    "\n",
    "#### e) **Capa de Salida (Output Layer)**\n",
    "\n",
    "Depende de la tarea:\n",
    "\n",
    "* **Clasificaci√≥n:** utiliza una **Softmax** que transforma los valores en probabilidades:\n",
    "\n",
    "* **Regresi√≥n o detecci√≥n:** puede tener una salida lineal o m√∫ltiple (por ejemplo, coordenadas de cajas delimitadoras).\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Propagaci√≥n hacia Atr√°s (Backpropagation)**\n",
    "\n",
    "El entrenamiento de una CNN sigue el mismo principio que una red neuronal tradicional:\n",
    "\n",
    "1. **Propagaci√≥n hacia adelante:** la imagen pasa por todas las capas.\n",
    "2. **C√°lculo del error:** se compara la salida con la etiqueta real mediante una **funci√≥n de p√©rdida** (por ejemplo, entrop√≠a cruzada).\n",
    "3. **Retropropagaci√≥n:** se calculan los gradientes y se actualizan los pesos de los filtros usando un **optimizador** (SGD, Adam, etc.).\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **Par√°metros Importantes**\n",
    "\n",
    "* **Stride:** desplazamiento del filtro sobre la imagen.\n",
    "* **Padding:** relleno que se a√±ade para conservar el tama√±o original tras la convoluci√≥n.\n",
    "* **N√∫mero de filtros:** determina la cantidad de caracter√≠sticas que la red puede aprender en cada capa.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. **Arquitecturas Populares**\n",
    "\n",
    "| Arquitectura              | A√±o  | Caracter√≠sticas                                                    |\n",
    "| ------------------------- | ---- | ------------------------------------------------------------------ |\n",
    "| **LeNet-5**               | 1998 | Primera CNN exitosa para reconocimiento de d√≠gitos.                |\n",
    "| **AlexNet**               | 2012 | Ganadora de ImageNet; introdujo ReLU y dropout.                    |\n",
    "| **VGGNet**                | 2014 | Uso sistem√°tico de filtros 3x3.                                    |\n",
    "| **ResNet**                | 2015 | Introduce *residual connections* que permiten redes muy profundas. |\n",
    "| **Inception (GoogLeNet)** | 2015 | Combinaci√≥n de m√∫ltiples tama√±os de filtro en paralelo.            |\n",
    "\n",
    "---\n",
    "\n",
    "### 6. **Ventajas de las CNNs**\n",
    "\n",
    "‚úÖ Capturan **relaciones espaciales locales** (formas, texturas).\n",
    "\n",
    "‚úÖ Reducen par√°metros mediante **compartici√≥n de pesos**.\n",
    "\n",
    "‚úÖ Funcionan bien con **im√°genes, video y se√±ales**.\n",
    "\n",
    "‚úÖ Pueden adaptarse a otras tareas: detecci√≥n, segmentaci√≥n, reconocimiento facial, etc.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### 7. **Desventajas o Retos**\n",
    "\n",
    "‚ö†Ô∏è Requieren **gran cantidad de datos** para un buen desempe√±o.\n",
    "\n",
    "‚ö†Ô∏è Alto costo computacional (GPU recomendadas).\n",
    "\n",
    "‚ö†Ô∏è Son modelos de tipo ‚Äúcaja negra‚Äù: dif√≠cil interpretar qu√© aprende cada filtro.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### 8. **Aplicaciones Comunes**\n",
    "\n",
    "* Clasificaci√≥n de im√°genes m√©dicas (tumores, radiograf√≠as).\n",
    "* Reconocimiento facial y biometr√≠a.\n",
    "* Veh√≠culos aut√≥nomos (detecci√≥n de objetos).\n",
    "* Visi√≥n industrial (detecci√≥n de defectos).\n",
    "* Sistemas de vigilancia y seguridad.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52e3466",
   "metadata": {},
   "source": [
    "## Requisitos previos y librer√≠as\n",
    "\n",
    "* Python 3.9+ (recomendado 3.10/3.11)\n",
    "* CUDA disponible para entrenamiento acelerado (opcional, recomendado)\n",
    "* Librer√≠as (sugeridas): `torch`, `torchvision`, `numpy`, `matplotlib`, `scikit-learn`.\n",
    "\n",
    "Ejemplo de `requirements.txt` m√≠nimo para laboratorio:\n",
    "\n",
    "```\n",
    "torch>=1.12\n",
    "torchvision>=0.13\n",
    "numpy>=1.23\n",
    "matplotlib>=3.5\n",
    "scikit-learn>=1.0\n",
    "tensorboard>=2.11    # opcional para visualizaci√≥n de m√©tricas\n",
    "```\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f6d9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Script: install_dependencies.py\n",
    "Prop√≥sito: Crear y gestionar el archivo 'requirements.txt' e instalar las dependencias necesarias para el proyecto de visi√≥n por computador.\n",
    "\n",
    "Buenas pr√°cticas aplicadas:\n",
    "- Cumplimiento del est√°ndar PEP 8 (formato y estilo)\n",
    "- Uso de context manager para manejo de archivos\n",
    "- Comentarios explicativos en cada paso\n",
    "- Instalaci√≥n controlada mediante subprocess (m√°s seguro que usar !pip directamente)\n",
    "\"\"\"\n",
    "\n",
    "# -------------------- Librer√≠as est√°ndar --------------------\n",
    "import subprocess  # Permite ejecutar comandos del sistema desde Python\n",
    "from pathlib import Path  # Manejo robusto de rutas en distintos sistemas operativos\n",
    "\n",
    "\n",
    "def install_dependencies() -> None:\n",
    "    \"\"\"\n",
    "    Crea un archivo 'requirements.txt' con las librer√≠as necesarias\n",
    "    e instala los paquetes usando pip.\n",
    "    \"\"\"\n",
    "\n",
    "    # Definimos las dependencias requeridas por el proyecto\n",
    "    dependencies = \"\"\"opencv-python>=4.5\n",
    "numpy>=1.23\n",
    "matplotlib>=3.5\n",
    "pytest>=7.0\n",
    "mypy>=0.990\n",
    "torch>=1.12\n",
    "torchvision>=0.13\n",
    "scikit-learn>=1.0\n",
    "tensorboard>=2.11\n",
    "\"\"\"\n",
    "\n",
    "    # Creamos el archivo requirements.txt en el directorio actual\n",
    "    requirements_path = Path(\"requirements.txt\")\n",
    "\n",
    "    with requirements_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(dependencies)\n",
    "\n",
    "    print(\"‚úÖ Archivo 'requirements.txt' creado correctamente con las siguientes librer√≠as:\\n\")\n",
    "    print(dependencies)\n",
    "\n",
    "    # Ejecutamos el comando pip install -r requirements.txt de forma segura\n",
    "    try:\n",
    "        print(\"üöÄ Instalando dependencias, esto puede tardar unos minutos...\\n\")\n",
    "        subprocess.check_call([\"pip\", \"install\", \"-r\", str(requirements_path)])\n",
    "        print(\"\\n‚úÖ Instalaci√≥n completada con √©xito.\")\n",
    "    except subprocess.CalledProcessError:\n",
    "        print(\"\\n‚ùå Error al instalar las dependencias. Verifica tu conexi√≥n a internet o permisos del entorno.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ö†Ô∏è Error inesperado: {e}\")\n",
    "\n",
    "\n",
    "# -------------------- Punto de entrada --------------------\n",
    "if __name__ == \"__main__\":\n",
    "    install_dependencies()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a85634f",
   "metadata": {},
   "source": [
    "## Laboratorio pr√°ctico ‚Äî Entrenamiento de una CNN (paso a paso)\n",
    "\n",
    "### Objetivo del laboratorio\n",
    "\n",
    "Entrenar una CNN para clasificaci√≥n de im√°genes usando dos enfoques:\n",
    "\n",
    "* **A.** Entrenamiento desde cero con un modelo simple.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25eb2e15",
   "metadata": {},
   "source": [
    "### C√≥digo: script de entrenamiento\n",
    "\n",
    "A continuaci√≥n se ofrece un **script modular** (PyTorch) que se puede usar tanto en notebook como en consola. Est√° escrito siguiendo PEP 8, incluye tipado y logging.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab80aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Entrenamiento de ResNet18 optimizado para CIFAR-10\n",
    "\"\"\"\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Este script entrena un modelo de visi√≥n por computador (CNN)\n",
    "# utilizando PyTorch y el dataset CIFAR-10.\n",
    "# Incluye:\n",
    "# - control de memoria y errores\n",
    "# - logs detallados\n",
    "# - guardado de checkpoints\n",
    "# - early stopping\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "# ===============================\n",
    "# üì¶ IMPORTACI√ìN DE LIBRER√çAS\n",
    "# ===============================\n",
    "\n",
    "import gc               # 'garbage collector' ‚Üí permite liberar memoria no utilizada\n",
    "import logging          # para registrar eventos durante la ejecuci√≥n\n",
    "import os               # operaciones con archivos y directorios\n",
    "import random           # generaci√≥n de n√∫meros aleatorios (usado para reproducibilidad)\n",
    "import time             # medir tiempos de ejecuci√≥n\n",
    "from dataclasses import dataclass  # simplifica la creaci√≥n de clases de configuraci√≥n\n",
    "from pathlib import Path            # manejo multiplataforma de rutas de archivos\n",
    "from typing import Tuple            # tipado opcional para mayor claridad\n",
    "\n",
    "# Librer√≠as cient√≠ficas y de aprendizaje profundo\n",
    "import numpy as np                  # operaciones con matrices y vectores\n",
    "import torch                        # biblioteca principal para deep learning\n",
    "from torch import nn, optim         # 'nn' define capas y modelos, 'optim' define optimizadores\n",
    "from torch.utils.data import DataLoader  # crea lotes (batches) de datos\n",
    "import torchvision                  # herramientas para visi√≥n por computador\n",
    "from torchvision import transforms, datasets, models  # incluye datasets, transformaciones y modelos preentrenados\n",
    "\n",
    "# ===============================\n",
    "# üß† CONFIGURACI√ìN DE LOGGING\n",
    "# ===============================\n",
    "# Se usa para mostrar mensajes de progreso y depuraci√≥n.\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "logger = logging.getLogger('train_cnn')  # se crea un logger llamado 'train_cnn'\n",
    "\n",
    "# ===============================\n",
    "# ‚öôÔ∏è CLASE DE CONFIGURACI√ìN\n",
    "# ===============================\n",
    "@dataclass\n",
    "class Config:\n",
    "    \"\"\"Par√°metros globales para el entrenamiento\"\"\"\n",
    "    data_dir: str = 'data'                 # Carpeta donde se descarga CIFAR-10\n",
    "    model_name: str = 'simple_cnn'         # Nombre del modelo ('simple_cnn' o 'resnet18')\n",
    "    pretrained: bool = False               # Usar pesos preentrenados (solo para ResNet)\n",
    "    num_classes: int = 10                  # CIFAR-10 tiene 10 clases posibles\n",
    "    epochs: int = 1                        # N√∫mero de √©pocas de entrenamiento (1 para demo r√°pida)\n",
    "    batch_size: int = 32                   # Tama√±o de lote (batch)\n",
    "    lr: float = 1e-3                       # Tasa de aprendizaje (learning rate)\n",
    "    device: str = 'cuda' if torch.cuda.is_available() else 'cpu'  # Usa GPU si est√° disponible\n",
    "    output_dir: str = 'checkpoints'        # Carpeta donde se guardar√°n los modelos entrenados\n",
    "\n",
    "# ===============================\n",
    "# üîÅ FIJAR SEMILLA\n",
    "# ===============================\n",
    "    \"\"\"\n",
    "        Una semilla aleatoria (random seed) es un n√∫mero inicial que sirve como punto de partida para los generadores de n√∫meros aleatorios en un programa.\n",
    "\n",
    "        Aunque hablamos de ‚Äúaleatoriedad‚Äù, en realidad los computadores no generan n√∫meros realmente aleatorios (porque siguen instrucciones deterministas).\n",
    "        Lo que hacen es usar una f√≥rmula matem√°tica que produce una secuencia de n√∫meros pseudoaleatorios, es decir, que parecen aleatorios, pero que siempre ser√°n los mismos si inicias con la misma semilla.\n",
    "    \"\"\"\n",
    "    \n",
    "def set_seed(seed: int = 42):\n",
    "    \"\"\"Fija la semilla aleatoria para obtener resultados reproducibles.\"\"\"\n",
    "    random.seed(seed)               # fija semilla de Python\n",
    "    np.random.seed(seed)            # fija semilla de NumPy\n",
    "    torch.manual_seed(seed)         # fija semilla de PyTorch (CPU)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)  # fija semilla en todas las GPUs\n",
    "    torch.backends.cudnn.deterministic = True  # hace las operaciones deterministas\n",
    "\n",
    "# ===============================\n",
    "# ‚ôªÔ∏è FUNCI√ìN PARA LIBERAR MEMORIA\n",
    "# ===============================\n",
    "def clear_memory():\n",
    "    \"\"\"Libera memoria no usada para evitar errores 'out of memory'.\"\"\"\n",
    "    gc.collect()                     # libera objetos no referenciados de la memoria\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()     # limpia cach√© de la GPU\n",
    "\n",
    "# ===============================\n",
    "# üìÇ FUNCI√ìN PARA CARGAR LOS DATOS\n",
    "# ===============================\n",
    "def get_dataloaders(cfg: Config):\n",
    "    \"\"\"Descarga CIFAR-10 y prepara los DataLoaders de entrenamiento y validaci√≥n.\"\"\"\n",
    "\n",
    "    # ---- Transformaciones de datos (preprocesamiento) ----\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),  # recorta aleatoriamente con padding de 4 p√≠xeles\n",
    "        transforms.RandomHorizontalFlip(),     # voltea horizontalmente la imagen al azar\n",
    "        transforms.ToTensor(),                 # convierte imagen PIL a tensor (0‚Äì1)\n",
    "    ])\n",
    "    \n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),                 # para validaci√≥n, solo se convierte a tensor\n",
    "    ])\n",
    "\n",
    "    # ---- Carga de datasets ----\n",
    "    \n",
    "    \"\"\"\n",
    "        Datos para entrenar la red neuronal\n",
    "    \"\"\"\n",
    "    train_set = datasets.CIFAR10(\n",
    "        root=cfg.data_dir,        # carpeta destino\n",
    "        train=True,               # conjunto de entrenamiento\n",
    "        download=True,            # descarga si no est√° disponible\n",
    "        transform=train_transform # aplica transformaciones\n",
    "    )\n",
    "    \"\"\"\n",
    "        Datos para validar (evaluar) el desempe√±o del modelo durante o despu√©s del entrenamiento.\n",
    "    \"\"\"\n",
    "    val_set = datasets.CIFAR10(\n",
    "        root=cfg.data_dir,        # carpeta destino\n",
    "        train=False,              # conjunto de validaci√≥n\n",
    "        download=True,\n",
    "        transform=val_transform\n",
    "    )\n",
    "\n",
    "    # ---- Creaci√≥n de DataLoaders ----\n",
    "    \"\"\"\n",
    "        DataLoaders encargados de servir los datos por lotes (batches) durante el entrenamiento y validaci√≥n de la red neuronal.\n",
    "    \"\"\"\n",
    "    train_loader = DataLoader(\n",
    "        train_set, batch_size=cfg.batch_size, shuffle=True, num_workers=0\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_set, batch_size=cfg.batch_size, shuffle=False, num_workers=0\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader  # devuelve ambos cargadores\n",
    "\n",
    "# ===============================\n",
    "# üèóÔ∏è CONSTRUCCI√ìN DEL MODELO\n",
    "# ===============================\n",
    "def build_model(cfg: Config):\n",
    "    \"\"\"Crea el modelo especificado (ResNet18 o CNN simple).\"\"\"\n",
    "\n",
    "    # Si el modelo elegido es ResNet18:\n",
    "    if cfg.model_name == 'resnet18':\n",
    "        model = models.resnet18(  # carga arquitectura ResNet18\n",
    "            weights=models.ResNet18_Weights.DEFAULT if cfg.pretrained else None\n",
    "        )\n",
    "        num_ftrs = model.fc.in_features           # obtiene n√∫mero de caracter√≠sticas de la capa FC\n",
    "        model.fc = nn.Linear(num_ftrs, cfg.num_classes)  # reemplaza la √∫ltima capa para 10 clases\n",
    "\n",
    "        # Congela capas iniciales (para ahorrar recursos)\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "        # Descongela solo las capas finales (entrenamiento parcial)\n",
    "        for param in model.layer4.parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.fc.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    # Si el modelo elegido es una CNN simple:\n",
    "    elif cfg.model_name == 'simple_cnn':\n",
    "        model = nn.Sequential(  # modelo secuencial (apila capas)\n",
    "            nn.Conv2d(3, 32, 3, padding=1),  # capa convolucional: 3 canales de entrada (RGB) ‚Üí 32 filtros\n",
    "            nn.ReLU(),                       # funci√≥n de activaci√≥n no lineal\n",
    "            nn.MaxPool2d(2),                 # reduce la dimensi√≥n de la imagen a la mitad\n",
    "            nn.Conv2d(32, 64, 3, padding=1), # segunda capa convolucional: 64 filtros\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),                 # otra reducci√≥n espacial\n",
    "            nn.Flatten(),                    # convierte el mapa 2D en un vector 1D\n",
    "            nn.Linear(64 * 8 * 8, 256),      # capa totalmente conectada (FC)\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, cfg.num_classes),  # capa de salida con 10 neuronas (una por clase)\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f'Modelo no soportado: {cfg.model_name}')  # validaci√≥n de nombre de modelo\n",
    "\n",
    "    return model  # devuelve el modelo construido\n",
    "\n",
    "# ===============================\n",
    "# üîÅ ENTRENAMIENTO DE UNA √âPOCA\n",
    "# ===============================\n",
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    \"\"\"Entrena el modelo durante una √©poca completa.\"\"\"\n",
    "    model.train()               # establece modo entrenamiento\n",
    "    running_loss = 0.0          # acumulador de p√©rdida\n",
    "    correct = 0                 # contador de predicciones correctas\n",
    "    total = 0                   # total de muestras procesadas\n",
    "\n",
    "    # Iteraci√≥n sobre cada lote (batch)\n",
    "    for batch_idx, (images, labels) in enumerate(dataloader):\n",
    "        images, labels = images.to(device), labels.to(device)  # pasa datos a CPU o GPU\n",
    "        optimizer.zero_grad()                                  # limpia gradientes anteriores\n",
    "\n",
    "        try:\n",
    "            outputs = model(images)              # pasa im√°genes por la red (forward)\n",
    "            loss = criterion(outputs, labels)    # calcula la p√©rdida entre predicci√≥n y etiqueta\n",
    "            loss.backward()                      # calcula gradientes (backpropagation)\n",
    "            optimizer.step()                     # actualiza los pesos del modelo\n",
    "        except RuntimeError as e:\n",
    "            if \"out of memory\" in str(e).lower():  # maneja errores de memoria GPU\n",
    "                logger.warning('Error de memoria, limpiando cach√©...')\n",
    "                clear_memory()\n",
    "                continue\n",
    "\n",
    "        # ---- M√©tricas ----\n",
    "        running_loss += loss.item() * images.size(0)  # acumula p√©rdida ponderada\n",
    "        _, preds = torch.max(outputs, 1)              # obtiene predicci√≥n m√°s probable\n",
    "        correct += (preds == labels).sum().item()     # cuenta aciertos\n",
    "        total += labels.size(0)                       # acumula total de ejemplos\n",
    "\n",
    "        # ---- Registro intermedio ----\n",
    "        if batch_idx % 100 == 0:\n",
    "            acc = correct / total if total > 0 else 0\n",
    "            logger.info(f'Batch {batch_idx}/{len(dataloader)} - Loss: {loss.item():.4f} - Acc: {acc:.4f}')\n",
    "\n",
    "    return running_loss / total, correct / total  # devuelve p√©rdida y precisi√≥n promedio\n",
    "\n",
    "# ===============================\n",
    "# üß™ VALIDACI√ìN DEL MODELO\n",
    "# ===============================\n",
    "@torch.no_grad()  # desactiva c√°lculo de gradientes (m√°s r√°pido)\n",
    "def validate(model, dataloader, criterion, device):\n",
    "    \"\"\"Eval√∫a el modelo en el conjunto de validaci√≥n.\"\"\"\n",
    "    model.eval()  # cambia a modo evaluaci√≥n\n",
    "    running_loss = 0.0 # acumulador de p√©rdida\n",
    "    correct = 0 # contador de predicciones correctas\n",
    "    total = 0 # total de muestras procesadas\n",
    "\n",
    "    for images, labels in dataloader:\n",
    "        images, labels = images.to(device), labels.to(device) # pasa datos a CPU o GPU\n",
    "        outputs = model(images)               # predicciones\n",
    "        loss = criterion(outputs, labels)     # c√°lculo de p√©rdida\n",
    "        running_loss += loss.item() * images.size(0) # acumula p√©rdida ponderada\n",
    "        _, preds = torch.max(outputs, 1) # obtiene predicci√≥n m√°s probable\n",
    "        correct += (preds == labels).sum().item() # cuenta aciertos\n",
    "        total += labels.size(0) # acumula total de ejemplos\n",
    "\n",
    "    return running_loss / total, correct / total  # devuelve m√©tricas de validaci√≥n\n",
    "\n",
    "# ===============================\n",
    "# üíæ GUARDADO DE CHECKPOINT\n",
    "# ===============================\n",
    "def save_checkpoint(state, path):\n",
    "    \"\"\"Guarda el estado actual del modelo y del optimizador.\"\"\"\n",
    "    Path(path).parent.mkdir(parents=True, exist_ok=True)  # crea carpeta si no existe\n",
    "    torch.save(state, path)                               # guarda diccionario con el estado\n",
    "    logger.info(f'Checkpoint guardado: {path}')           # mensaje informativo\n",
    "\n",
    "# ===============================\n",
    "# üöÄ FUNCI√ìN PRINCIPAL\n",
    "# ===============================\n",
    "def main():\n",
    "    \"\"\"Ejecuta todo el proceso de entrenamiento.\"\"\"\n",
    "    start_time = time.time()              # mide tiempo de ejecuci√≥n total\n",
    "    cfg = Config()                        # carga configuraci√≥n por defecto\n",
    "\n",
    "    # ---- Muestra configuraci√≥n ----\n",
    "    logger.info(f'Dispositivo: {cfg.device}')\n",
    "    logger.info(f'Configuraci√≥n: batch_size={cfg.batch_size}, epochs={cfg.epochs}, model={cfg.model_name}')\n",
    "\n",
    "    if cfg.model_name == 'simple_cnn':    # mensaje adicional para la versi√≥n r√°pida\n",
    "        logger.info('CNN Simple - Configuraci√≥n optimizada para velocidad')\n",
    "        logger.info('Entrenamiento r√°pido para demostraci√≥n')\n",
    "\n",
    "    set_seed()  # asegura reproducibilidad\n",
    "\n",
    "    try:\n",
    "        # ---- Preparaci√≥n de entorno ----\n",
    "        train_loader, val_loader = get_dataloaders(cfg)             # carga datos\n",
    "        model = build_model(cfg).to(cfg.device)                     # crea modelo y lo mueve a CPU/GPU\n",
    "        criterion = nn.CrossEntropyLoss()                           # define funci√≥n de p√©rdida\n",
    "        optimizer = optim.SGD(model.parameters(), lr=cfg.lr, momentum=0.9)  # optimizador SGD\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2)  # reduce LR si no mejora\n",
    "\n",
    "        best_val_loss = float('inf')  # mejor p√©rdida hasta ahora\n",
    "        epochs_no_improve = 0         # contador para early stopping\n",
    "\n",
    "        # ---- Bucle principal de entrenamiento ----\n",
    "        for epoch in range(1, cfg.epochs + 1):\n",
    "            epoch_start = time.time()\n",
    "\n",
    "            # Entrenamiento y validaci√≥n\n",
    "            train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, cfg.device)\n",
    "            val_loss, val_acc = validate(model, val_loader, criterion, cfg.device)\n",
    "\n",
    "            epoch_time = time.time() - epoch_start\n",
    "            logger.info(f'√âpoca {epoch}/{cfg.epochs} ({epoch_time:.1f}s): '\n",
    "                        f'train_loss={train_loss:.4f} train_acc={train_acc:.4f} '\n",
    "                        f'val_loss={val_loss:.4f} val_acc={val_acc:.4f}')\n",
    "\n",
    "            scheduler.step(val_loss)  # ajusta la tasa de aprendizaje seg√∫n la p√©rdida\n",
    "\n",
    "            # ---- Guardar estado actual ----\n",
    "            save_checkpoint({\n",
    "                'epoch': epoch,\n",
    "                'model_state': model.state_dict(),          # pesos del modelo\n",
    "                'optimizer_state': optimizer.state_dict()   # estado del optimizador\n",
    "            }, f'{cfg.output_dir}/model_epoch{epoch}.pt')\n",
    "\n",
    "            # ---- Early Stopping ----\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                epochs_no_improve = 0\n",
    "            else:\n",
    "                epochs_no_improve += 1\n",
    "                if epochs_no_improve >= 3:\n",
    "                    logger.info(f'Early stopping en √©poca {epoch}')\n",
    "                    break\n",
    "\n",
    "            clear_memory()  # libera memoria al final de cada √©poca\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f'Error durante entrenamiento: {e}')  # registra errores\n",
    "        raise  # relanza la excepci√≥n\n",
    "\n",
    "    finally:\n",
    "        clear_memory()  # limpieza final\n",
    "        total_time = time.time() - start_time\n",
    "        logger.info(f'Entrenamiento completado en {total_time:.1f} segundos')\n",
    "\n",
    "# ===============================\n",
    "# ‚ñ∂Ô∏è PUNTO DE ENTRADA DEL SCRIPT\n",
    "# ===============================\n",
    "if __name__ == '__main__':\n",
    "    main()  # ejecuta la funci√≥n principal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0e3574",
   "metadata": {},
   "source": [
    "# **Ejecute el proyecto:**\n",
    "\n",
    "```\n",
    "python main.py\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b4549b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "## Buenas pr√°cticas integradas en el laboratorio\n",
    "\n",
    "1. **PEP 8 y tipado**: funciones con docstrings, nombres claros, y `typing` para par√°metros y retornos.\n",
    "2. **Reproducibilidad**: fijar seeds para `random`, `numpy` y `torch`; documentar ver\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
