{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c6a74bf",
   "metadata": {},
   "source": [
    "# Clase 1 — Fundamentos de Visión por Computador\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6c4884",
   "metadata": {},
   "source": [
    "## Resumen\n",
    "\n",
    "* Conceptos básicos de imágenes digitales y formatos de archivo.\n",
    "* Uso práctico de **OpenCV** en Python para carga, manipulación y análisis básico de imágenes.\n",
    "* Ejercicios guiados paso a paso con código limpio, tipado y pruebas básicas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f4897c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Objetivos de aprendizaje\n",
    "\n",
    "Al finalizar la sesión, los estudiantes serán capaces de:\n",
    "\n",
    "1. Explicar qué es una imagen digital, cómo se representa en memoria y cuáles son las diferencias entre formatos comunes (PNG, JPEG, TIFF, BMP, WEBP).\n",
    "2. Manipular imágenes con OpenCV: carga, guardado, cambio de tamaño, recorte, rotación y conversión de espacios de color.\n",
    "3. Realizar análisis básico de imágenes: histogramas, equalización, detección de bordes y segmentación simple por color.\n",
    "4. Escribir código Python legible, tipado y probado que implemente pipelines simples de visión por computador.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd916374",
   "metadata": {},
   "source": [
    "## Requisitos previos y recursos\n",
    "\n",
    "Requisitos técnicos:\n",
    "\n",
    "* Python 3.9+ (recomendado 3.10 o 3.11).\n",
    "* Espacio en disco para imágenes de ejemplo (100 MB es más que suficiente para prácticas).\n",
    "* Acceso a JupyterLab o un IDE (VS Code recomendado).\n",
    "\n",
    "Paquetes que instalaremos (se detalla `requirements.txt` más abajo):\n",
    "\n",
    "* `opencv-python` (OpenCV - para carga, manipulación y análisis básico de imágenes)\n",
    "* `numpy` (ETL + Analisis estadístico de dataset)\n",
    "* `matplotlib` (para visualización en notebooks)\n",
    "* `pytest` (para pruebas)\n",
    "* `mypy` (opcional, para chequeo de tipos)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513a4fac",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Contenido sugerido para `requirements.txt`:\n",
    "\n",
    "```\n",
    "opencv-python>=4.5\n",
    "numpy>=1.23\n",
    "matplotlib>=3.5\n",
    "pytest>=7.0\n",
    "mypy>=0.990\n",
    "```\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4072c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalación de dependencias:\n",
    "\n",
    "# Crear requirements.txt\n",
    "with open(\"requirements.txt\", \"w\") as f:\n",
    "    f.write(\"\"\"opencv-python>=4.5\n",
    "numpy>=1.23\n",
    "matplotlib>=3.5\n",
    "pytest>=7.0\n",
    "mypy>=0.990\n",
    "\"\"\")\n",
    "\n",
    "# Instalar desde requirements.txt\n",
    "!pip install -r requirements.txt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8246daa",
   "metadata": {},
   "source": [
    "## Parte Teórica (detallada)\n",
    "\n",
    "### 1) ¿Qué es una imagen digital?\n",
    "\n",
    "* Una imagen digital se representa como una **matriz** (array) de valores discretos. Cada posición de la matriz es un *pixel* (picture element).\n",
    "* Cada píxel puede tener uno o varios canales (por ejemplo, escala de grises — 1 canal; RGB — 3 canales). En OpenCV las imágenes con color se cargan por defecto como **BGR** (Azul, Verde y Rojo).\n",
    "* **Muestreo** (sampling): número de píxeles por unidad de espacio; resolución.\n",
    "* **Cuantización** (quantization): niveles discretos por canal, típicamente 8 bits por canal (0–255). También existen imágenes de 16 bits o floating point para procesamiento científico.\n",
    "\n",
    "**Representación en memoria**: tipicamente `np.ndarray` con shape `(alto, ancho)` para escala de grises o `(alto, ancho, canales)` para color. dtype común: `uint8`, `uint16`, `float32`.\n",
    "\n",
    "### 2) Espacios de color\n",
    "\n",
    "* **RGB**: esquema aditivo más común para cámaras y pantallas.\n",
    "* **BGR**: convención usada por OpenCV (tener cuidado al mostrar con `matplotlib`, que espera RGB).\n",
    "* **HSV / HSL**: HSV (Tono, Saturación y Valor) y HSL (Tono, Saturación y Luminosidad). Útil para segmentación por color (separa tono del brillo/ saturación).\n",
    "* **YCbCr / YUV**: \n",
    "    \n",
    "    **YCbCr**\n",
    "    * Componentes: Se compone de tres componentes:\n",
    "    * Y: Luma o luminancia (brillo, imagen en blanco y negro).\n",
    "    * Cb: Diferencia de color azul (Blue-difference).\n",
    "    * Cr: Diferencia de color rojo (Red-difference).\n",
    "\n",
    "    * Uso: Es el espacio de color estándar para el video digital, como en DVD, Blu-ray, YouTube y otros formatos modernos.separación de luminancia y crominancia — útil en compresión de video.\n",
    "\n",
    "    **YUV**\n",
    "    * Componentes: Tradicionalmente se compone de tres componentes:\n",
    "    * Y: Luminancia.\n",
    "    * U y V: Señales de crominancia.\n",
    "\n",
    "    * Uso: Fue desarrollado para la televisión analógica a color, permitiendo la compatibilidad con televisores en blanco y negro.\n",
    "\n",
    "### 3) Formatos de archivo y compresión\n",
    "\n",
    "* **BMP**: sin compresión, simple, útil para pruebas.\n",
    "* **PNG**: compresión sin pérdida (lossless), soporta transparencia (canal alfa).\n",
    "* **JPEG**: compresión con pérdida (lossy), útil para imágenes fotográficas; cuidado con artefactos al recomprimir.\n",
    "* **TIFF**: flexible, puede ser lossless o contener múltiples páginas y mayor profundidad de bits.\n",
    "* **WEBP**: moderno, soporta pérdida y sin pérdida.\n",
    "\n",
    "\n",
    "### 4) Operaciones básicas y conceptos de procesamiento\n",
    "\n",
    "* **Operaciones puntuales**: transformación por píxel (p. ej., invertir, escala), rápidas y paralelizables.\n",
    "* **Operaciones espaciales (convoluciones)**: aplicar kernels / filtros (blur, sharpen, detección de bordes).\n",
    "* **Operaciones geométricas**: rotación, traslación, escalado y transformaciones afines.\n",
    "* **Morfología matemática**: erosion, dilatation, apertura y cierre — útiles en limpieza de ruido y post-procesamiento de máscaras.\n",
    "\n",
    "### 5) Detección de bordes y segmentación básica\n",
    "\n",
    "* **Filtro Sobel**: gradientes en X e Y — aproximación de derivadas.\n",
    "* **Filtro Laplacian**: segunda derivada — detecta zonas rápidas de cambio.\n",
    "* **Canny**: detector de bordes robusto en varios pasos (smoothing, gradiente, non-maximum suppression, hysteresis thresholding).\n",
    "* **Umbralización (thresholding)**: global, adaptativo y método de Otsu para selección automática de umbral.\n",
    "\n",
    "### 6) Contornos y análisis geométrico\n",
    "\n",
    "* Encontrar contornos a partir de una máscara binaria; extraer bounding box, centroides, área y perímetro.\n",
    "* Uso típico: detección simple de objetos, conteo y medidas geométricas.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f505068",
   "metadata": {},
   "source": [
    "\n",
    "## Demo guiada con OpenCV (visión general del flujo)\n",
    "\n",
    "**Objetivo de la demo**: mostrar un pipeline mínimo que carga una imagen, convierte a RGB para visualización en Jupyter, redimensiona, aplica ecualización global y Canny, encuentra contornos y guarda el resultado.\n",
    "\n",
    "> El código completo y comentado con tipado y pruebas está en la sección \"Ejemplo de código\".\n",
    "\n",
    "---\n",
    "\n",
    "## Código\n",
    "\n",
    "```main.py```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d247bc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Módulo: main.py\n",
    "Funciones básicas para carga, manipulación y análisis de imágenes con OpenCV.\n",
    "\n",
    "Buenas prácticas aplicadas:\n",
    "- Tipado estático (type hints)\n",
    "- Docstrings con formato estándar\n",
    "- Uso de logging para trazabilidad\n",
    "- Manejo de errores robusto\n",
    "\"\"\"\n",
    "\n",
    "# Permite usar anotaciones de tipo antes de definir funciones o clases (útil para referencias adelantadas)\n",
    "from __future__ import annotations\n",
    "\n",
    "# ------------------- Librerías estándar -------------------\n",
    "import logging  # Permite registrar información, advertencias y errores en lugar de usar print()\n",
    "from dataclasses import dataclass  # Facilita la creación de clases simples (genera __init__, __repr__, etc.)\n",
    "from pathlib import Path  # Manejo de rutas multiplataforma (más seguro y flexible que cadenas de texto)\n",
    "from typing import Optional, Tuple, List  # Tipado estático: mejora documentación y validación en tiempo de desarrollo\n",
    "\n",
    "# ------------------- Librerías externas -------------------\n",
    "import cv2  # OpenCV: librería principal para procesamiento de imágenes y visión por computador\n",
    "import numpy as np  # NumPy: base de datos numérica para manejar arrays multidimensionales (las imágenes son matrices)\n",
    "import matplotlib.pyplot as plt  # Matplotlib: librería para visualizar imágenes y gráficos\n",
    "\n",
    "# ------------------- Configuración del logger -------------------\n",
    "# Configura el sistema de registro para mostrar mensajes informativos y errores en consola\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(levelname)s:%(name)s:%(message)s\")\n",
    "\n",
    "# Crea un objeto logger identificado con el nombre \"main\"\n",
    "logger = logging.getLogger(\"main\")\n",
    "\n",
    "# ------------------- Clase de configuración -------------------\n",
    "@dataclass  # Convierte automáticamente la clase en una estructura de datos con inicializador automático\n",
    "class ImageProcessingConfig:\n",
    "    \"\"\"\n",
    "    Clase de configuración para operaciones de imagen.\n",
    "\n",
    "    Attributes:\n",
    "        interpolation_resize: Tipo de interpolación usada al redimensionar imágenes.\n",
    "    \"\"\"\n",
    "    interpolation_resize: int = cv2.INTER_AREA  # Método de interpolación recomendado para reducir imágenes\n",
    "\n",
    "# ------------------- Funciones principales -------------------\n",
    "\n",
    "def load_image(path: str, as_gray: bool = False) -> np.ndarray:\n",
    "    \"\"\"Carga una imagen desde `path`.\"\"\"\n",
    "    p = Path(path)  # Convierte la ruta recibida en un objeto Path para operaciones seguras de archivos\n",
    "\n",
    "    if not p.exists():  # Verifica si el archivo realmente existe en el disco\n",
    "        logger.error(\"Archivo no encontrado: %s\", path)  # Registra el error en los logs\n",
    "        raise FileNotFoundError(f\"Archivo no encontrado: {path}\")  # Lanza excepción si no existe\n",
    "\n",
    "    # Define el modo de lectura dependiendo si se solicita escala de grises o color\n",
    "    flag = cv2.IMREAD_GRAYSCALE if as_gray else cv2.IMREAD_COLOR\n",
    "\n",
    "    img = cv2.imread(str(p), flags=flag)  # Carga la imagen usando OpenCV\n",
    "    if img is None:  # Si OpenCV no puede leer la imagen, devuelve None\n",
    "        logger.error(\"cv2.imread devolvió None para %s\", path)  # Registra el fallo\n",
    "        raise IOError(f\"No se pudo leer la imagen: {path}\")  # Lanza error\n",
    "\n",
    "    # Muestra en logs información útil de la imagen cargada\n",
    "    logger.info(\"Imagen cargada: %s -- shape=%s dtype=%s\", path, img.shape, img.dtype)\n",
    "    return img  # Devuelve la imagen cargada como arreglo NumPy\n",
    "\n",
    "\n",
    "def save_image(path: str, image: np.ndarray) -> None:\n",
    "    \"\"\"Guarda una imagen en disco, creando directorios si es necesario.\"\"\"\n",
    "    p = Path(path)  # Convierte la ruta a objeto Path\n",
    "    p.parent.mkdir(parents=True, exist_ok=True)  # Crea directorios necesarios si no existen\n",
    "\n",
    "    ok = cv2.imwrite(str(p), image)  # Guarda la imagen en la ruta especificada\n",
    "    if not ok:  # Si el guardado falla, cv2.imwrite devuelve False\n",
    "        logger.error(\"Error guardando la imagen en %s\", path)\n",
    "        raise IOError(f\"Error guardando la imagen en {path}\")\n",
    "\n",
    "    logger.info(\"Imagen guardada en %s\", path)  # Registra en logs el éxito del guardado\n",
    "\n",
    "\n",
    "def to_rgb(image_bgr: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Convierte BGR (formato de OpenCV) a RGB (formato estándar).\"\"\"\n",
    "    if image_bgr.ndim == 2:  # Si la imagen tiene 2 dimensiones, ya está en escala de grises\n",
    "        return image_bgr  # No se necesita conversión\n",
    "    return cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)  # Convierte de BGR a RGB\n",
    "\n",
    "\n",
    "def to_gray(image_bgr: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Convierte una imagen BGR a escala de grises.\"\"\"\n",
    "    if image_bgr.ndim == 2:  # Si ya es escala de grises\n",
    "        return image_bgr\n",
    "    return cv2.cvtColor(image_bgr, cv2.COLOR_BGR2GRAY)  # Usa OpenCV para la conversión\n",
    "\n",
    "\n",
    "def resize_image(\n",
    "    image: np.ndarray,\n",
    "    width: Optional[int] = None,\n",
    "    height: Optional[int] = None,\n",
    "    keep_aspect: bool = True,\n",
    "    config: ImageProcessingConfig = ImageProcessingConfig()\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Redimensiona una imagen conservando la relación de aspecto si se solicita.\"\"\"\n",
    "    (h, w) = image.shape[:2]  # Obtiene alto y ancho actuales\n",
    "\n",
    "    # Si no se especifican dimensiones, se devuelve la imagen original\n",
    "    if width is None and height is None:\n",
    "        return image\n",
    "\n",
    "    # Si se desea mantener la relación de aspecto original\n",
    "    if keep_aspect:\n",
    "        if width is None:\n",
    "            ratio = height / float(h)  # Calcula proporción basada en altura\n",
    "            dim = (int(w * ratio), height)  # Ajusta ancho proporcionalmente\n",
    "        elif height is None:\n",
    "            ratio = width / float(w)\n",
    "            dim = (width, int(h * ratio))\n",
    "        else:\n",
    "            dim = (width, height)\n",
    "    else:\n",
    "        # Si no se mantiene la proporción, se usan las dimensiones exactas\n",
    "        dim = (width if width else w, height if height else h)\n",
    "\n",
    "    # Redimensiona la imagen con el método de interpolación configurado\n",
    "    resized = cv2.resize(image, dim, interpolation=config.interpolation_resize)\n",
    "\n",
    "    # Registra en los logs el cambio de tamaño\n",
    "    logger.info(\"resize_image: %s -> %s\", (w, h), resized.shape[:2])\n",
    "    return resized\n",
    "\n",
    "\n",
    "def rotate_image(image: np.ndarray, angle: float, center: Optional[Tuple[int, int]] = None,\n",
    "                 scale: float = 1.0) -> np.ndarray:\n",
    "    \"\"\"Rota una imagen en torno a un punto dado (por defecto, su centro).\"\"\"\n",
    "    (h, w) = image.shape[:2]  # Obtiene dimensiones de la imagen\n",
    "\n",
    "    if center is None:  # Si no se especifica el centro de rotación\n",
    "        center = (w // 2, h // 2)  # Usa el centro geométrico\n",
    "\n",
    "    # Calcula la matriz de transformación para rotación\n",
    "    M = cv2.getRotationMatrix2D(center, angle, scale)\n",
    "\n",
    "    # Aplica la transformación de rotación sobre la imagen\n",
    "    rotated = cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT)\n",
    "\n",
    "    # Registra el evento de rotación\n",
    "    logger.info(\"rotate_image: angle=%s center=%s scale=%s\", angle, center, scale)\n",
    "    return rotated  # Devuelve la imagen rotada\n",
    "\n",
    "\n",
    "def crop_image(image: np.ndarray, x: int, y: int, w: int, h: int) -> np.ndarray:\n",
    "    \"\"\"Recorta una región rectangular (x,y,w,h).\"\"\"\n",
    "    # Recorta los píxeles en el rango indicado y devuelve una copia\n",
    "    return image[y:y + h, x:x + w].copy()\n",
    "\n",
    "\n",
    "def histogram_equalization_gray(image_gray: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Equalización de histograma en imágenes en escala de grises usada para mejorar el contraste de una imagen.\"\"\"\n",
    "    if image_gray.ndim != 2:  # Valida que sea imagen en gris\n",
    "        raise ValueError(\"Debe ser una imagen en escala de grises (2D)\")\n",
    "\n",
    "    # Aplica la equalización con OpenCV\n",
    "    eq = cv2.equalizeHist(image_gray)\n",
    "\n",
    "    logger.info(\"histogram_equalization_gray: completado\")  # Log informativo\n",
    "    return eq  # Devuelve la imagen con histograma equalizado\n",
    "\n",
    "\n",
    "def apply_clahe_gray(image_gray: np.ndarray, clip_limit: float = 2.0,\n",
    "                     tile_grid_size: Tuple[int, int] = (8, 8)) -> np.ndarray:\n",
    "    \"\"\"Aplica CLAHE: equalización adaptativa del histograma (mejora el contraste local).\"\"\"\n",
    "    # Crea el objeto CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
    "    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)\n",
    "\n",
    "    # Aplica el método sobre la imagen\n",
    "    res = clahe.apply(image_gray)\n",
    "\n",
    "    # Registra los parámetros utilizados\n",
    "    logger.info(\"apply_clahe_gray: clip_limit=%s tile_grid_size=%s\", clip_limit, tile_grid_size)\n",
    "    return res\n",
    "\n",
    "\n",
    "def gaussian_blur(image: np.ndarray, ksize: Tuple[int, int] = (5, 5)) -> np.ndarray:\n",
    "    \"\"\"Aplica un desenfoque Gaussiano (suaviza ruido y bordes).\"\"\"\n",
    "    # Aplica un filtro gaussiano con tamaño de kernel (5x5 por defecto)\n",
    "    return cv2.GaussianBlur(image, ksize, 0)\n",
    "\n",
    "\n",
    "def canny_edges(image_gray: np.ndarray, threshold1: float = 100.0, threshold2: float = 200.0) -> np.ndarray:\n",
    "    \"\"\"Detecta bordes con el algoritmo de Canny.\"\"\"\n",
    "    edges = cv2.Canny(image_gray, threshold1, threshold2)  # Detecta bordes\n",
    "    logger.info(\"canny_edges: thresholds=(%s,%s)\", threshold1, threshold2)  # Registra umbrales\n",
    "    return edges  # Devuelve imagen binaria con los bordes detectados\n",
    "\n",
    "# función crea una máscara binaria que resalta solo los píxeles dentro de un rango específico de color definido en el espacio HSV (Hue, Saturation, Value). muy útil en proyectos de Big Data visual, robótica, seguridad, industria 4.0, agricultura inteligente, etc.\n",
    "\n",
    "def mask_by_hsv(image_bgr: np.ndarray, lower_hsv: Tuple[int, int, int],\n",
    "                upper_hsv: Tuple[int, int, int]) -> np.ndarray:\n",
    "    \"\"\"Genera una máscara binaria filtrando por rango de color en espacio HSV.\"\"\"\n",
    "    hsv = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2HSV)  # Convierte de BGR a HSV\n",
    "    # Crea máscara binaria donde los píxeles dentro del rango son blancos (255)\n",
    "    mask = cv2.inRange(hsv, np.array(lower_hsv, dtype=np.uint8), np.array(upper_hsv, dtype=np.uint8))\n",
    "    logger.info(\"mask_by_hsv: rango=%s-%s\", lower_hsv, upper_hsv)\n",
    "    return mask\n",
    "\n",
    "\n",
    "def find_and_draw_contours(image_bgr: np.ndarray, binary_mask: np.ndarray,\n",
    "                           min_area: int = 100) -> Tuple[np.ndarray, List[Tuple[int, int, int, int]]]:\n",
    "    \"\"\"Encuentra contornos y dibuja rectángulos alrededor de objetos grandes.\"\"\"\n",
    "    # Busca contornos externos en la máscara binaria\n",
    "    contours, hierarchy = cv2.findContours(binary_mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    boxes: List[Tuple[int, int, int, int]] = []  # Lista para almacenar rectángulos detectados\n",
    "    annotated = image_bgr.copy()  # Copia de la imagen original para dibujar resultados\n",
    "\n",
    "    for cnt in contours:  # Recorre cada contorno encontrado\n",
    "        area = cv2.contourArea(cnt)  # Calcula el área del contorno\n",
    "        if area < min_area:  # Si el área es menor que el mínimo permitido\n",
    "            continue  # Ignora contornos pequeños\n",
    "        x, y, w, h = cv2.boundingRect(cnt)  # Calcula el rectángulo delimitador\n",
    "        boxes.append((x, y, w, h))  # Guarda coordenadas del rectángulo\n",
    "        cv2.rectangle(annotated, (x, y), (x + w, y + h), (0, 255, 0), 2)  # Dibuja el rectángulo verde\n",
    "\n",
    "    logger.info(\"find_and_draw_contours: contornos válidos=%d\", len(boxes))  # Log del número de contornos válidos\n",
    "    return annotated, boxes  # Devuelve la imagen anotada y las coordenadas\n",
    "\n",
    "\n",
    "def show_image_matplotlib(image: np.ndarray, title: str = \"Image\") -> None:\n",
    "    \"\"\"Muestra una imagen usando Matplotlib (útil en notebooks o Jupyter).\"\"\"\n",
    "    img = to_rgb(image)  # Asegura formato RGB antes de mostrar\n",
    "    plt.figure(figsize=(8, 6))  # Define tamaño del gráfico\n",
    "    if img.ndim == 2:  # Si es imagen en gris\n",
    "        plt.imshow(img, cmap=\"gray\")\n",
    "    else:\n",
    "        plt.imshow(img)\n",
    "    plt.title(title)  # Añade título\n",
    "    plt.axis(\"off\")  # Oculta ejes\n",
    "    plt.show()  # Muestra la imagen\n",
    "\n",
    "\n",
    "# ------------------- Pipeline de ejemplo -------------------\n",
    "def pipeline_demo(input_path: str, output_path: str) -> None:\n",
    "    \"\"\"Pipeline completo: carga, convierte, equaliza, detecta bordes y guarda resultado.\"\"\"\n",
    "    img = load_image(input_path, as_gray=False)  # Carga la imagen en color\n",
    "    gray = to_gray(img)  # Convierte a escala de grises\n",
    "    eq = apply_clahe_gray(gray)  # Mejora el contraste local\n",
    "    edges = canny_edges(eq, 50, 150)  # Detecta bordes con Canny\n",
    "\n",
    "    # Superposición de bordes sobre la imagen original para visualización\n",
    "    edges_bgr = cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR)  # Convierte bordes a 3 canales\n",
    "    overlay = cv2.addWeighted(img, 0.6, edges_bgr, 0.4, 0)  # Combina imagen original y bordes\n",
    "\n",
    "    # Guarda varias versiones del resultado en disco\n",
    "    base_name = Path(output_path).stem  # Obtiene nombre base sin extensión\n",
    "    save_image(f\"{base_name}_original.jpg\", img)\n",
    "    save_image(f\"{base_name}_bordes.jpg\", edges)\n",
    "    save_image(f\"{base_name}_superpuesto.jpg\", overlay)\n",
    "    save_image(output_path, overlay)  # Guarda la versión final\n",
    "\n",
    "    logger.info(\"pipeline_demo completado: %s\", output_path)  # Informa finalización del proceso\n",
    "\n",
    "\n",
    "# ------------------- Punto de entrada -------------------\n",
    "if __name__ == \"__main__\":  # Solo se ejecuta si el script se corre directamente\n",
    "    import argparse  # Librería estándar para procesar argumentos de línea de comandos\n",
    "\n",
    "    # Configura los argumentos esperados\n",
    "    parser = argparse.ArgumentParser(description=\"Demo de operaciones básicas con OpenCV\")\n",
    "    parser.add_argument(\"--input\", required=True, help=\"Ruta de entrada de la imagen\")\n",
    "    parser.add_argument(\"--output\", required=True, help=\"Ruta de salida de la imagen procesada\")\n",
    "    args = parser.parse_args()  # Parsea los argumentos\n",
    "\n",
    "    # Ejecuta el pipeline con las rutas dadas por el usuario\n",
    "    pipeline_demo(args.input, args.output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006965e0",
   "metadata": {},
   "source": [
    "> **Notas sobre el código**:\n",
    ">\n",
    "> * Use `to_rgb` para visualizar en Jupyter o matplotlib ya que OpenCV usa BGR por defecto.\n",
    "> * `apply_clahe_gray` es preferible a equalizeHist para evitar sobre-contraste en regiones pequeñas.\n",
    "> * `find_and_draw_contours` utiliza `RETR_EXTERNAL` para simplificar el ejemplo (solo contornos externos).\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54e6e88",
   "metadata": {},
   "source": [
    "# ejecutar la app como script\n",
    "\n",
    "```\n",
    "python main.py --input sample.jpg --output salida.jpg\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37665ff9",
   "metadata": {},
   "source": [
    "## Ejercicios prácticos\n",
    "\n",
    "### Laboratorio 1 — Manipulación básica\n",
    "\n",
    "**Objetivo**: Ejecutar funciones para cargar, redimensionar, recortar, rotar y guardar imágenes.\n",
    "\n",
    "**Instrucciones**:\n",
    "\n",
    "1. Crear un repositorio de práctica con la estructura mínima:\n",
    "\n",
    "```\n",
    "cv-lab1/\n",
    "├── data/\n",
    "│   └── sample.jpg      # imagen de ejemplo\n",
    "├── notebooks/\n",
    "│   └── lab1.ipynb      # notebook con instrucciones y visualizaciones\n",
    "├── src/\n",
    "│   └── cv_fundamentals.py  # copiar/usar el módulo de ejemplo\n",
    "├── requirements.txt\n",
    "└── README.md\n",
    "```\n",
    "\n",
    "2. En `notebooks/lab1.ipynb` realizar los siguientes pasos con código y celdas de explicación:\n",
    "\n",
    "* Cargar la imagen `data/sample.jpg` y mostrar su shape y dtype.\n",
    "* Mostrar la imagen original en Jupyter (usar `show_image_matplotlib`).\n",
    "* Redimensionar la imagen a 800 px de ancho manteniendo aspecto.\n",
    "* Rotar la imagen 30 grados en sentido antihorario y mostrar el resultado.\n",
    "* Recortar una región de interés (x=100, y=50, w=200, h=200) y guardar el recorte en `data/crop.jpg`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3edcbe",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Repositorio de práctica **cv-lab1** y el notebook **lab1.ipynb** con todo lo solicitado.\n",
    "\n",
    "Qué incluye \n",
    "\n",
    "* `cv-lab1/`\n",
    "\n",
    "  * `data/sample.jpg` — imagen de ejemplo generada (con una zona roja central, un rectángulo azul y otro verde).\n",
    "  * `data/crop.jpg` — (se generará al ejecutar el notebook; el notebook guarda el recorte en esa ruta).\n",
    "  * `notebooks/lab1.ipynb` — notebook con celdas de explicación y todo el código paso a paso: carga, mostrar, redimensionar a 800 px, rotar 30° CCW, recortar ROI (100,50,200,200) y guardar.\n",
    "  * `src/cv_fundamentals.py` — módulo Python con funciones documentadas y tipadas: `load_image`, `save_image`, `resize_image`, `rotate_image`, `crop_image`, `show_image_matplotlib`. Incluye logging y docstrings siguiendo PEP 8.\n",
    "  * `requirements.txt` — dependencias sugeridas (OpenCV, numpy, matplotlib, pytest, mypy).\n",
    "  * `README.md` — instrucciones de uso rápido.\n",
    "\n",
    "Sugerencias de cómo usarlo\n",
    "\n",
    "* Abrir `notebooks/lab1.ipynb` con JupyterLab/Jupyter Notebook y ejecutar celda a celda (o `Run → Run All` si ya están instaladas las dependencias).\n",
    "* Instalar `requirements.txt`.\n",
    "* Revisar los logs (el módulo usa `logging`).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54de4a20",
   "metadata": {},
   "source": [
    "## Laboratorio 2 — Análisis y segmentación simple\n",
    "\n",
    "### Objetivo\n",
    "\n",
    "Aprender a **extraer información útil de imágenes digitales** mediante histogramas, ecualización adaptativa, detección de bordes y segmentación por color, integrando operaciones de preprocesamiento y análisis.\n",
    "\n",
    "---\n",
    "\n",
    "### Estructura del repositorio\n",
    "\n",
    "Se recomienda extender el repositorio anterior (`cv-lab1`) añadiendo un nuevo notebook:\n",
    "\n",
    "```\n",
    "cv-lab1/\n",
    "├── data/\n",
    "│   └── sample.jpg\n",
    "├── notebooks/\n",
    "│   ├── lab1.ipynb\n",
    "│   └── lab2.ipynb          # ← nuevo notebook con este laboratorio\n",
    "├── src/\n",
    "│   └── cv_fundamentals.py\n",
    "├── requirements.txt\n",
    "└── README.md\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Notebook `lab2.ipynb`\n",
    "\n",
    "#### Paso 1: Histograma de luminancia o escala de grises\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fb0008",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from src.cv_fundamentals import load_image, show_image_matplotlib\n",
    "\n",
    "# Cargar imagen en escala de grises\n",
    "gray = cv2.imread(\"../data/sample.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Calcular histograma\n",
    "hist = cv2.calcHist([gray], [0], None, [256], [0, 256])\n",
    "\n",
    "# Mostrar histograma\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(hist, color='black')\n",
    "plt.title(\"Histograma en escala de grises\")\n",
    "plt.xlabel(\"Intensidad\")\n",
    "plt.ylabel(\"Frecuencia\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81be88d9",
   "metadata": {},
   "source": [
    "**Explicación**: Un histograma muestra la distribución de intensidades de píxeles. Es fundamental para evaluar contraste.\n",
    "\n",
    "---\n",
    "\n",
    "#### Paso 2: Ecualización de histograma adaptativa (CLAHE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85746bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear objeto CLAHE\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "\n",
    "# Aplicar CLAHE\n",
    "clahe_img = clahe.apply(gray)\n",
    "\n",
    "# Comparar imágenes\n",
    "show_image_matplotlib(gray, title=\"Original (Grises)\")\n",
    "show_image_matplotlib(clahe_img, title=\"CLAHE\")\n",
    "\n",
    "# Comparar histogramas\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(gray.ravel(), 256, [0, 256], color='gray')\n",
    "plt.title(\"Histograma Original\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(clahe_img.ravel(), 256, [0, 256], color='black')\n",
    "plt.title(\"Histograma CLAHE\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8604f9d",
   "metadata": {},
   "source": [
    "**Explicación**: CLAHE (Contrast Limited Adaptive Histogram Equalization) mejora el contraste local y evita la sobre-amplificación del ruido.\n",
    "\n",
    "---\n",
    "\n",
    "#### Paso 3: Detección de bordes con Canny\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3be556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bordes con umbral bajo/alto\n",
    "edges1 = cv2.Canny(gray, 50, 150)\n",
    "edges2 = cv2.Canny(gray, 100, 200)\n",
    "\n",
    "# Mostrar comparativa\n",
    "show_image_matplotlib(edges1, title=\"Canny 50/150\")\n",
    "show_image_matplotlib(edges2, title=\"Canny 100/200\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d56e589",
   "metadata": {},
   "source": [
    "**Explicación**: El algoritmo de Canny busca gradientes de intensidad para detectar bordes. Cambiar los umbrales afecta la sensibilidad.\n",
    "\n",
    "---\n",
    "\n",
    "#### Paso 4: Segmentación por color (ejemplo: detectar objeto rojo)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e871b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar imagen en BGR\n",
    "image = load_image(\"../data/sample.jpg\")\n",
    "\n",
    "# Convertir a HSV\n",
    "hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Rango para rojo (dos segmentos debido a circularidad de Hue)\n",
    "lower_red1 = np.array([0, 100, 100])\n",
    "upper_red1 = np.array([10, 255, 255])\n",
    "lower_red2 = np.array([160, 100, 100])\n",
    "upper_red2 = np.array([179, 255, 255])\n",
    "\n",
    "# Máscara combinada\n",
    "mask1 = cv2.inRange(hsv, lower_red1, upper_red1)\n",
    "mask2 = cv2.inRange(hsv, lower_red2, upper_red2)\n",
    "mask = cv2.bitwise_or(mask1, mask2)\n",
    "\n",
    "# Limpiar máscara (morfología)\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "mask_clean = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "mask_clean = cv2.morphologyEx(mask_clean, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "# Encontrar contornos\n",
    "contours, _ = cv2.findContours(mask_clean, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Dibujar bounding boxes\n",
    "output = image.copy()\n",
    "for c in contours:\n",
    "    x, y, w, h = cv2.boundingRect(c)\n",
    "    cv2.rectangle(output, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "show_image_matplotlib(output, title=\"Segmentación por color (Rojo)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417ff2c7",
   "metadata": {},
   "source": [
    "**Explicación**:\n",
    "\n",
    "* HSV facilita segmentar colores.\n",
    "* Se aplican operaciones morfológicas (`open` y `close`) para limpiar ruido.\n",
    "* Los contornos permiten ubicar y medir objetos.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b689bc",
   "metadata": {},
   "source": [
    "## Recursos adicionales y lecturas recomendadas\n",
    "\n",
    "* Libro clásico: *Digital Image Processing* (Gonzalez & Woods) — teoría y ejemplos.\n",
    "* Documentación oficial de OpenCV (tutoriales y referencias de funciones).\n",
    "* Artículos/tutos sobre CLAHE, Canny y transformaciones geométricas.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24630b45",
   "metadata": {},
   "source": [
    "## Extensiones y siguientes clases\n",
    "\n",
    "* Clase 2: Segmentación avanzada y operaciones morfológicas.\n",
    "* Clase 3: Detección y reconocimiento de objetos (contornos avanzados, HOG, SIFT/SURF, ORB y un primer acercamiento a redes neuronales convolucionales para visión - transfer learning).\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
