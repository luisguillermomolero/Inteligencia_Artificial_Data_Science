{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ae5ebc8",
   "metadata": {},
   "source": [
    "# Clase 4 — Taller práctico: Desarrollo de una aplicación web interactiva para cargar y clasificar imágenes\n",
    "\n",
    "---\n",
    "\n",
    "## Objetivos de aprendizaje\n",
    "\n",
    "Al finalizar la sesión los estudiantes deberán ser capaces de:\n",
    "\n",
    "1. Diseñar la arquitectura de una aplicación web para visión por computador (frontend, API, modelo).\n",
    "2. Implementar una API REST segura y eficiente que sirva un modelo de clasificación.\n",
    "3. Implementar un cliente web interactivo (HTML/JS o React) que suba imágenes y muestre resultados.\n",
    "4. Contenerizar la aplicación con Docker y ejecutar el sistema localmente o en la nube.\n",
    "5. Aplicar buenas prácticas de ingeniería: PEP 8, tipado, logging, pruebas automatizadas y consideraciones de privacidad/seguridad (OWASP).\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229d5a5b",
   "metadata": {},
   "source": [
    "## Requisitos previos y recursos\n",
    "\n",
    "* Python 3.9+\n",
    "* Node.js + npm (para la parte de React opcional)\n",
    "* Docker (para contenerización)\n",
    "* Conocimiento básico de HTTP, REST y JSON\n",
    "\n",
    "Paquetes principales (backend): `fastapi`, `uvicorn`, `pydantic`, `opencv-python` (si es necesario), `torch`/`torchvision` (si se usa modelo PyTorch), `python-multipart`.\n",
    "\n",
    "---\n",
    "\n",
    "## Arquitectura propuesta (alta prioridad)\n",
    "\n",
    "1. **Frontend (cliente web)**\n",
    "\n",
    "   * Página que permite seleccionar o arrastrar la imagen, muestra preview y permite enviar al backend.\n",
    "   * Consume endpoints REST: `/health`, `/predict/upload`, `/predict/base64`.\n",
    "2. **Backend (API)**\n",
    "\n",
    "   * FastAPI con endpoints de inferencia, validación y logging.\n",
    "   * Carga del modelo en `startup` (singleton) para evitar recargas por petición.\n",
    "   * Manejo de límites de tamaño y validación MIME.\n",
    "3. **Modelo**\n",
    "\n",
    "   * Modelo de clasificación (ResNet18 u otro) cargado en memoria; para producción usar TorchScript/ONNX.\n",
    "4. **Infraestructura**\n",
    "\n",
    "   * Contenedores: backend y frontend (opcional). Docker Compose para orquestación local.\n",
    "   * Observabilidad: logs estructurados y métricas básicas.\n",
    "\n",
    "---\n",
    "\n",
    "## Buenas prácticas, estándares y seguridad\n",
    "\n",
    "* **PEP 8 / Pydantic / Tipado**: todo código Python debe tener docstrings, tipado y pasar flake8/black.\n",
    "* **OWASP**: limitar tamaño de subida, validar tipo de archivo, evitar ejecución de datos inseguros, proteger endpoints con autenticación si necesario.\n",
    "* **Privacidad**: no almacenar imágenes sin consentimiento; si se almacenan, cifrar y tener política de retención.\n",
    "* **Testing**: `pytest` para unidad y `fastapi.testclient` para integración.\n",
    "* **CI/CD**: usar GitHub Actions para ejecutar tests y linters en cada PR.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac9f7c0",
   "metadata": {},
   "source": [
    "## Parte práctica: \n",
    "\n",
    "A continuación, se presentan instrucciones detalladas, código de ejemplo y ejercicios. El ejemplo usa **FastAPI** en el backend y **vanilla JS** para el frontend (luego se presenta una versión React opcional).\n",
    "\n",
    "### 1) Estructura del proyecto\n",
    "\n",
    "```\n",
    "cv-webapp/\n",
    "├── backend/\n",
    "│   ├── app/\n",
    "│   │   ├── main.py\n",
    "│   │   ├── model.py\n",
    "│   │   ├── schemas.py\n",
    "│   │   └── utils.py\n",
    "│   ├── requirements.txt\n",
    "│   └── Dockerfile\n",
    "├── frontend/\n",
    "│   ├── index.html        # cliente HTML/JS simple\n",
    "│   ├── app.js\n",
    "│   └── Dockerfile (opcional)\n",
    "├── docker-compose.yml\n",
    "└── README.md\n",
    "```\n",
    "\n",
    "### 2) Backend: `app/main.py` (esqueleto)\n",
    "\n",
    "> Nota: no incluyas en producción `debug` ni `--reload`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd58d9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# backend/app/main.py\n",
    "from fastapi import FastAPI, UploadFile, File, HTTPException, Depends\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from starlette.requests import Request\n",
    "import logging\n",
    "\n",
    "from .model import VisionModel\n",
    "from .schemas import PredictResponse\n",
    "\n",
    "logger = logging.getLogger(\"cv_backend\")\n",
    "app = FastAPI(title=\"CV WebApp API\")\n",
    "\n",
    "# CORS: en clase permitir localhost; en producción restringir orígenes\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"http://localhost:3000\", \"http://127.0.0.1:3000\"],\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"],\n",
    ")\n",
    "\n",
    "model: VisionModel | None = None\n",
    "\n",
    "@app.on_event(\"startup\")\n",
    "def startup_event():\n",
    "    global model\n",
    "    model = VisionModel(device=\"cpu\")  # o \"cuda\" si GPU disponible\n",
    "    logger.info(\"Modelo cargado en startup\")\n",
    "\n",
    "@app.get(\"/health\")\n",
    "def health():\n",
    "    return {\"status\": \"ok\"}\n",
    "\n",
    "@app.post(\"/predict/upload\", response_model=PredictResponse)\n",
    "async def predict_upload(file: UploadFile = File(...)):\n",
    "    if not file.content_type.startswith(\"image/\"):\n",
    "        raise HTTPException(status_code=400, detail=\"Archivo no es imagen\")\n",
    "    contents = await file.read()\n",
    "    if len(contents) == 0:\n",
    "        raise HTTPException(status_code=400, detail=\"Archivo vacío\")\n",
    "    # límite de tamaño (ejemplo 5MB)\n",
    "    if len(contents) > 5 * 1024 * 1024:\n",
    "        raise HTTPException(status_code=413, detail=\"Archivo demasiado grande\")\n",
    "    result = model.predict_bytes(contents)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d51475d",
   "metadata": {},
   "source": [
    "### 3) Backend: `app/model.py` (carga del modelo y preprocesado)\n",
    "\n",
    "Incluye: carga en `__init__`, preprocesado con `torchvision.transforms`, y funciones: `predict_bytes`, `predict_image`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb04a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# backend/app/model.py\n",
    "from PIL import Image\n",
    "import io\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from torchvision import models\n",
    "\n",
    "class VisionModel:\n",
    "    def __init__(self, device: str = \"cpu\") -> None:\n",
    "        self.device = device\n",
    "        self.model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "        self.model.eval().to(self.device)\n",
    "        self.transform = T.Compose([\n",
    "            T.Resize(256),\n",
    "            T.CenterCrop(224),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
    "        ])\n",
    "\n",
    "    def preprocess(self, image: Image.Image) -> torch.Tensor:\n",
    "        return self.transform(image).unsqueeze(0).to(self.device)\n",
    "\n",
    "    def predict(self, image: Image.Image) -> dict:\n",
    "        x = self.preprocess(image)\n",
    "        with torch.no_grad():\n",
    "            logits = self.model(x)\n",
    "            probs = torch.nn.functional.softmax(logits, dim=1)\n",
    "            top_prob, top_cls = torch.max(probs, 1)\n",
    "        return {\"class_id\": int(top_cls[0].item()), \"score\": float(top_prob[0].item())}\n",
    "\n",
    "    def predict_bytes(self, data: bytes) -> dict:\n",
    "        image = Image.open(io.BytesIO(data)).convert(\"RGB\")\n",
    "        return self.predict(image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0fba29",
   "metadata": {},
   "source": [
    "### 4) Backend: Pydantic schemas `app/schemas.py`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b97ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class PredictResponse(BaseModel):\n",
    "    class_id: int\n",
    "    score: float\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c69314a",
   "metadata": {},
   "source": [
    "### 5) Frontend simple (HTML + JS)\n",
    "\n",
    "Archivo `frontend/index.html`:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ff3226",
   "metadata": {},
   "outputs": [],
   "source": [
    "<!doctype html>\n",
    "<html>\n",
    "<head>\n",
    "  <meta charset=\"utf-8\" />\n",
    "  <title>CV WebApp - Demo</title>\n",
    "</head>\n",
    "<body>\n",
    "  <h1>Sube una imagen</h1>\n",
    "  <input id=\"fileInput\" type=\"file\" accept=\"image/*\" />\n",
    "  <button id=\"sendBtn\">Enviar</button>\n",
    "  <div id=\"preview\"></div>\n",
    "  <div id=\"result\"></div>\n",
    "\n",
    "  <script src=\"/app.js\"></script>\n",
    "</body>\n",
    "</html>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5caf395",
   "metadata": {},
   "source": [
    "Archivo `frontend/app.js` (cliente minimal):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0e14e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "const fileInput = document.getElementById('fileInput');\n",
    "const sendBtn = document.getElementById('sendBtn');\n",
    "const preview = document.getElementById('preview');\n",
    "const result = document.getElementById('result');\n",
    "\n",
    "fileInput.addEventListener('change', () => {\n",
    "  const file = fileInput.files[0];\n",
    "  if (!file) return;\n",
    "  const img = document.createElement('img');\n",
    "  img.src = URL.createObjectURL(file);\n",
    "  img.style.maxWidth = '300px';\n",
    "  preview.innerHTML = '';\n",
    "  preview.appendChild(img);\n",
    "});\n",
    "\n",
    "sendBtn.addEventListener('click', async () => {\n",
    "  const file = fileInput.files[0];\n",
    "  if (!file) { alert('Selecciona una imagen'); return; }\n",
    "  const fd = new FormData();\n",
    "  fd.append('file', file);\n",
    "\n",
    "  const resp = await fetch('http://localhost:8000/predict/upload', {\n",
    "    method: 'POST', body: fd\n",
    "  });\n",
    "  const json = await resp.json();\n",
    "  result.innerText = JSON.stringify(json);\n",
    "});\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a3a450",
   "metadata": {},
   "source": [
    "> En la clase explique CORS y por qué el `fetch` falla si no se configura correctamente en `FastAPI`.\n",
    "\n",
    "### 6) Versión React (opcional)\n",
    "\n",
    "Proveer un `create-react-app` con un componente `ImageUploader.jsx` que haga lo mismo (mostrar preview, barra de progreso, resultado). Incluir manejo de estado, accesibilidad (aria-labels) y pruebas con React Testing Library.\n",
    "\n",
    "### 7) Contenerización y orquestación\n",
    "\n",
    "* `backend/Dockerfile` (liviana):\n",
    "\n",
    "```dockerfile\n",
    "FROM python:3.10-slim\n",
    "WORKDIR /app\n",
    "COPY requirements.txt ./\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "COPY app ./app\n",
    "CMD [\"uvicorn\", \"app.main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n",
    "```\n",
    "\n",
    "* `frontend/Dockerfile` (si sirve archivos estáticos con `http-server` o sirve desde Nginx)\n",
    "\n",
    "* `docker-compose.yml` (ejemplo):\n",
    "\n",
    "```yaml\n",
    "version: '3.8'\n",
    "services:\n",
    "  backend:\n",
    "    build: ./backend\n",
    "    ports: ['8000:8000']\n",
    "  frontend:\n",
    "    build: ./frontend\n",
    "    ports: ['3000:80']\n",
    "```\n",
    "\n",
    "Explicar cómo probar localmente con `docker compose up --build`.\n",
    "\n",
    "### 8) Exportar modelo a TorchScript para producción\n",
    "\n",
    "* Script `scripts/export_torchscript.py` traza `resnet18` y guarda `models/resnet18_traced.pt`.\n",
    "* En `VisionModel` primero intenta cargar `resnet18_traced.pt` con `torch.jit.load` y, si no existe, carga modelo Python.\n",
    "\n",
    "**Ventajas**: portabilidad y a veces mejoras de latencia en CPU. Explicar limitaciones (por ejemplo detección, operaciones dinámicas).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e1611b",
   "metadata": {},
   "source": [
    "## Actividades y ejercicios\n",
    "\n",
    "1. Implementar la aplicación completa y correrla localmente.\n",
    "2. Añadir endpoint `/predict/base64` y escribir cliente JavaScript para enviar imágenes como base64.\n",
    "3. Exportar y cargar el modelo TorchScript; medir latencias antes/después.\n",
    "4. Añadir autenticación básica (API Key) y documentar el proceso.\n",
    "5. Escribir tests y configurar GitHub Actions que ejecuten `pytest` y `flake8` en cada PR.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117f3564",
   "metadata": {},
   "source": [
    "## Recursos y lecturas recomendadas\n",
    "\n",
    "* FastAPI docs (endpoints, CORS, UploadFile)\n",
    "* PyTorch/TorchVision docs (model zoo, transforms, TorchScript)\n",
    "* OWASP (mitigación de vulnerabilidades web, file upload)\n",
    "* Artículos sobre deployment de modelos (TorchServe, ONNX Runtime, TensorFlow Serving)\n",
    "\n",
    "---\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
