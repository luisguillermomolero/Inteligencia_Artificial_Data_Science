{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dwRKIrrbgMxz"
   },
   "source": [
    "# Clase 4 – Taller práctico: creación de una aplicación interactiva para generar contenido\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PEtYrkbZp83R"
   },
   "source": [
    "## Estructura de carpetas y arquitectura del proyecto\n",
    "\n",
    "```\n",
    "app/\n",
    "│\n",
    "├── app.py               # Script principal que combina UI (Streamlit) y backend Gemini\n",
    "├── requirements.txt     # Dependencias necesarias\n",
    "└── .env.example         # Variables sensibles (API key, modelo)\n",
    "```\n",
    "\n",
    "* **`app.py`**: contendrá todo el código: la interfaz en Streamlit y lógica para llamar a Gemini.\n",
    "* **`requirements.txt`**: instalará `streamlit` y la librería para Gemini (`google-genai` o `google.generativeai`).\n",
    "* **`.env.example`**: incluirá cómo configurar `GEMINI_API_KEY` y `MODEL_NAME`.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iaovo36iqUSm"
   },
   "source": [
    "## Cómo usar la API de Gemini en Python\n",
    "\n",
    "* Es necesario generar una API key desde **Google AI Studio** ([https://aistudio.google.com/apikey].\n",
    "* Luego se debe instalar la librería:\n",
    "\n",
    "  ```bash\n",
    "  pip install google-genai\n",
    "  ```\n",
    "\n",
    "  o\n",
    "\n",
    "  ```bash\n",
    "  pip install google.generativeai\n",
    "  ```\n",
    "\n",
    "---\n",
    "## Código de `app.py`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "79MXEecOq0nz"
   },
   "outputs": [],
   "source": [
    "# app.py\n",
    "# ------------------------------------------\n",
    "# Generador de contenido con Google Gemini API.\n",
    "# Interfaz interactiva con Streamlit + lógica de generación.\n",
    "# Este archivo está comentado línea a línea para uso didáctico.\n",
    "#\n",
    "# Requisitos de instalación (ejecuta en tu terminal/entorno):\n",
    "#   pip install streamlit google-genai python-dotenv\n",
    "# Y define tu API key de Gemini en un archivo .env: GEMINI_API_KEY=tu_token\n",
    "# Opcional: MODEL_NAME=gemini-2.5-flash\n",
    "\n",
    "import os                      # Módulo estándar para leer variables de entorno y rutas del SO\n",
    "import streamlit as st         # Streamlit: framework para construir UI web en Python (sin HTML/JS)\n",
    "from datetime import datetime  # Para sellos de tiempo (historial)\n",
    "import json                    # Para serializar/guardar datos si lo necesitas (no obligatorio en este ejemplo)\n",
    "\n",
    "# Cargar variables de entorno desde un archivo .env ubicado en el mismo directorio del script.\n",
    "# Ej.: en .env coloca GEMINI_API_KEY=tu_clave y (opcional) MODEL_NAME=gemini-2.5-flash\n",
    "from dotenv import load_dotenv # Importamos utilidad para cargar .env\n",
    "load_dotenv()                  # Ejecutamos la carga; a partir de aquí os.getenv podrá leer esas variables\n",
    "\n",
    "# Intentamos importar la SDK de Gemini (google-genai).\n",
    "# Esta es la librería oficial nueva para la API de Gemini (distinta de google-generativeai).\n",
    "try:\n",
    "    from google import genai   # Import del cliente unificado de Gemini\n",
    "    GEMINI_AVAILABLE = True    # Bandera que indica que pudimos importar con éxito\n",
    "except ImportError:\n",
    "    GEMINI_AVAILABLE = False   # Si falla el import, marcamos que no está disponible (evitamos romper la app)\n",
    "\n",
    "# ---------------- Configuración inicial ----------------\n",
    "\n",
    "# Config de la página de Streamlit (debe ir antes de dibujar componentes).\n",
    "st.set_page_config(page_title=\"App con Gemini API\", layout=\"centered\")  # Título de pestaña y layout centrado\n",
    "\n",
    "# Título principal visible en la UI.\n",
    "st.title(\" Aplicación Generadora de Texto con Gemini API\")              # Encabezado H1 en la app\n",
    "\n",
    "# Texto introductorio para los usuarios (ayuda contextual en la UI).\n",
    "st.markdown(\n",
    "    \"Esta app usa la API de Gemini para crear contenido basado en un prompt. \"\n",
    "    \"Si no hay API disponible, no generará texto real.\"\n",
    ")  # Mensaje instructivo/informativo\n",
    "\n",
    "# Carga de configuración vía variables de entorno (con valores por defecto sensatos).\n",
    "MODEL_NAME = os.getenv(\"MODEL_NAME\", \"gemini-2.5-flash\")  # Modelo por defecto si no defines MODEL_NAME\n",
    "API_KEY = os.getenv(\"GEMINI_API_KEY\")                     # API key obligatoria para autenticarte ante Gemini\n",
    "\n",
    "# Validación temprana: si no hay API key, no podemos continuar. Mostramos error y detenemos la ejecución UI.\n",
    "if not API_KEY:\n",
    "    st.error(\"Necesitas configurar la clave API de Gemini (GEMINI_API_KEY).\")  # Mensaje de error en UI\n",
    "    st.stop()                                                                  # Detiene la app de manera limpia\n",
    "\n",
    "# Validación de la librería: si no está instalada/configurada, también detenemos.\n",
    "if not GEMINI_AVAILABLE:\n",
    "    st.error(\"No se encontró la librería `google.genai` o similar. Instálala primero.\")  # Sugerencia al usuario\n",
    "    st.stop()                                                                             # Detención segura\n",
    "\n",
    "# Inicializamos el cliente oficial de Gemini con la API key. A partir de aquí podremos llamar a modelos.\n",
    "client = genai.Client(api_key=API_KEY)  # Objeto cliente que expone .models.generate_content, etc.\n",
    "\n",
    "# ---------------- Interfaz de usuario ----------------\n",
    "\n",
    "# Área de texto para que el usuario escriba su instrucción o tema; height define la altura del cuadro.\n",
    "prompt = st.text_area(\n",
    "    \"Ingresa un prompt o instrucción\",          # Etiqueta visible\n",
    "    height=100,                                 # Altura del cuadro en píxeles aprox.\n",
    "    placeholder=\"Describe los beneficios de la IA en la educación...\"  # Ejemplo guía\n",
    ")\n",
    "\n",
    "# Controles en la barra lateral (sidebar) para ajustar parámetros de generación.\n",
    "# max_tokens limita la cantidad máxima de tokens que puede devolver el modelo (longitud de salida).\n",
    "max_tokens = st.sidebar.slider(\n",
    "    \"Longitud máxima (tokens)\",  # Etiqueta del control\n",
    "    50,                          # Mínimo permitido\n",
    "    500,                         # Máximo permitido\n",
    "    150                          # Valor por defecto\n",
    ")\n",
    "\n",
    "# temperature controla la aleatoriedad: valores altos = más creatividad, bajos = más determinismo.\n",
    "temperature = st.sidebar.slider(\n",
    "    \"Temperature\",  # Etiqueta del control\n",
    "    0.0,            # Mínimo (determinista)\n",
    "    2.0,            # Máximo (muy creativo)\n",
    "    1.0,            # Valor por defecto\n",
    "    step=0.1        # Incremento del slider\n",
    ")\n",
    "\n",
    "# Botón principal que dispara la generación de contenido. Cuando se hace clic, el bloque se ejecuta.\n",
    "if st.button(\"Generar contenido\"):\n",
    "    # Validación básica: evitamos llamadas con prompt vacío o solo espacios.\n",
    "    if not prompt.strip():\n",
    "        st.warning(\"Escribe algo antes de generar.\")  # Aviso en UI si el prompt está vacío\n",
    "    else:\n",
    "        # Muestra un spinner (indicador de carga) mientras hacemos la llamada a la API (operación I/O que puede tardar).\n",
    "        with st.spinner(\"Generando...\"):\n",
    "            try:\n",
    "                # Llamada a la API de Gemini mediante el cliente unificado.\n",
    "                # - model: nombre del modelo (ej. \"gemini-2.5-flash\")\n",
    "                # - contents: texto de entrada (prompt)\n",
    "                # - config: objeto de configuración con parámetros de decodificación (temperature, max_output_tokens, etc.)\n",
    "                response = client.models.generate_content(\n",
    "                    model=MODEL_NAME,                         # Modelo a utilizar (rápido y económico para demos)\n",
    "                    contents=prompt,                          # Contenido de entrada (tu prompt)\n",
    "                    config=genai.types.GenerateContentConfig( # Configuración de la generación\n",
    "                        temperature=temperature,              # Control de aleatoriedad/creatividad\n",
    "                        max_output_tokens=max_tokens          # Límite de tokens de salida (longitud de respuesta)\n",
    "                    )\n",
    "                )\n",
    "                text = response.text  # Extraemos el texto plano de la respuesta (SDK ya lo normaliza)\n",
    "            except Exception as e:\n",
    "                # Si ocurre algún error (conexión, cuotas, parámetros inválidos), lo mostramos al usuario.\n",
    "                st.error(f\"Error al generar contenido: {e}\")  # Muestra el mensaje de error\n",
    "                text = \"\"                                     # Aseguramos que text sea str vacío para la lógica siguiente\n",
    "\n",
    "        # Si la API devolvió texto, lo mostramos y registramos en un historial en memoria.\n",
    "        if text:\n",
    "            st.subheader(\"Texto generado:\")  # Encabezado para la sección de resultado\n",
    "            st.write(text)                   # Pinta el texto generado en la UI (admite markdown básico)\n",
    "\n",
    "            # Historial sencillo: guardamos en st.session_state (vida de la sesión del navegador).\n",
    "            if \"history\" not in st.session_state:     # Si no existe la clave 'history', la inicializamos\n",
    "                st.session_state.history = []         # Creamos una lista vacía para almacenar entradas\n",
    "            st.session_state.history.insert(0, {      # Insertamos al inicio para ver lo más reciente primero\n",
    "                \"timestamp\": datetime.now().isoformat(),  # Fecha/hora en formato ISO 8601\n",
    "                \"prompt\": prompt,                         # Prompt utilizado\n",
    "                \"output\": text,                           # Texto generado por el modelo\n",
    "                \"model\": MODEL_NAME,                      # Nombre del modelo usado (para trazabilidad)\n",
    "                \"temperature\": temperature,               # Parámetro usado\n",
    "                \"max_tokens\": max_tokens                  # Parámetro usado\n",
    "            })\n",
    "\n",
    "# Si hay elementos en el historial, los presentamos debajo separados por líneas para facilitar lectura.\n",
    "if st.session_state.get(\"history\"):            # Comprobamos si existe y no está vacío\n",
    "    st.markdown(\"---\")                         # Separador visual\n",
    "    st.subheader(\"Historial de generación:\")   # Título de la sección de historial\n",
    "    for entry in st.session_state.history:     # Iteramos cada entrada (diccionario) en el historial\n",
    "        st.write(f\"{entry['timestamp']} — Modelo: {entry['model']}\")  # Metadatos de la generación\n",
    "        st.write(\"**Prompt:**\", entry['prompt'])                      # Prompt original\n",
    "        st.write(\"**Output:**\", entry['output'])                      # Salida generada\n",
    "        st.write(\"---\")                                               # Separador entre entradas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "shcBHmZhrPXp"
   },
   "source": [
    "---\n",
    "\n",
    "## `requirements.txt`\n",
    "\n",
    "```\n",
    "streamlit>=1.10\n",
    "google-genai\n",
    "python-dotenv\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## `.env.example`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GEMINI_API_KEY=AIzaSyBTsU84Dbwi6Rw1Kf6zGkbJnYagljLuaLE\n",
    "MODEL_NAME=gemini-2.5-flash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ypAv83aBrTw5"
   },
   "source": [
    "## Instalar dependencias:\n",
    "\n",
    "```\n",
    "pip install -r requirements.txt\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xqb_PCylrhiI"
   },
   "source": [
    "## Ejecutar app\n",
    "\n",
    "```\n",
    "streamlit run app.py\n",
    "```\n",
    "\n",
    "Abrir `http://localhost:8501` en el navegador.\n",
    "\n",
    "Asegúrate de tener configuradas `GEMINI_API_KEY` y opcionalmente `MODEL_NAME` en tu ambiente o en `.env`.\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNw1Flh2F1Fb9VvcAW54CGD",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
