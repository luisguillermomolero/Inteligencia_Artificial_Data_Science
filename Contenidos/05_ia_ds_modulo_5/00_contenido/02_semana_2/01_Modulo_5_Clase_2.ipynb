{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d70d977",
   "metadata": {},
   "source": [
    "# Módulo 5 — Clase 2: Modelos Generativos\n",
    "\n",
    "# 1) Introducción a modelos generativos\n",
    "\n",
    "## **Teoría Sencilla de Modelos Generativos**\n",
    "\n",
    "### 1. **¿Qué es un modelo generativo?**\n",
    "\n",
    "Imagina que tienes una máquina que, después de “aprender” a partir de ejemplos reales, puede **inventar nuevos ejemplos parecidos**.\n",
    "Por ejemplo:\n",
    "\n",
    "* Si le das miles de fotos de gatos, puede generar fotos nuevas de gatos que **no existen** en la realidad.\n",
    "* Si le das textos de noticias, puede inventar nuevos titulares que suenen reales.\n",
    "\n",
    "**Idea clave:** El modelo no solo aprende a reconocer algo, sino **a crear algo nuevo** siguiendo el mismo estilo o patrón.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Tipos de modelos generativos**\n",
    "\n",
    "Podemos dividirlos en dos grandes grupos:\n",
    "\n",
    "1. **Modelos con densidad explícita**\n",
    "\n",
    "   * Intentan aprender **exactamente** cómo es la probabilidad de cada dato.\n",
    "   * Ejemplos:\n",
    "\n",
    "     * Distribuciones gaussianas\n",
    "     * Modelos de mezcla (GMM)\n",
    "     * *Normalizing Flows*\n",
    "2. **Modelos con densidad implícita**\n",
    "\n",
    "   * No calculan la probabilidad exacta, pero saben **imitar** los datos muy bien.\n",
    "   * Ejemplos:\n",
    "\n",
    "     * **GANs (Generative Adversarial Networks)**\n",
    "     * Algunos **VAEs (Variational Autoencoders)**\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **¿Por qué nos importan?**\n",
    "\n",
    "Estos modelos se usan en muchísimos casos reales:\n",
    "\n",
    "* **Aumento de datos** para entrenar otros modelos (ej. generar más fotos de rayos X para entrenar un detector de enfermedades).\n",
    "* **Diseño de productos**: generar imágenes de ropa, muebles, coches antes de fabricarlos.\n",
    "* **Generación de texto**: resúmenes automáticos, guiones, respuestas inteligentes.\n",
    "* **Síntesis de voz**: imitar la voz de una persona.\n",
    "* **Generación de código**: crear funciones o programas a partir de descripciones.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. **Conceptos clave**\n",
    "\n",
    "* **Log-verosimilitud:** mide qué tan bien el modelo imita los datos reales.\n",
    "* **Divergencias (KL, JS):** formas de medir la diferencia entre lo que el modelo genera y lo real.\n",
    "* **Entrenamiento adversarial:** en GANs, dos redes (Generador y Discriminador) compiten para mejorar.\n",
    "* **Auto-regresión:** en Transformers, el modelo predice un elemento a la vez, usando lo anterior como contexto.\n",
    "* **Espacio latente (z):** una representación interna comprimida de los datos, donde cada punto corresponde a una posible salida.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f8932a",
   "metadata": {},
   "source": [
    "## **Ejemplo sencillo de modelos generativos**\n",
    "\n",
    "### Escenario\n",
    "\n",
    "Imagina que tienes una **pastelería** y quieres crear nuevos diseños de cupcakes para tu menú.\n",
    "\n",
    "* Tienes **muchas fotos reales** de cupcakes que ya vendes.\n",
    "* Quieres inventar **nuevos cupcakes** que parezcan reales, aunque nunca los hayas hecho.\n",
    "\n",
    "---\n",
    "\n",
    "### Cómo sería con cada tipo de modelo\n",
    "\n",
    "1. **Modelo discriminativo**\n",
    "\n",
    "   * Sería como un empleado que mira una foto y dice:\n",
    "\n",
    "     > \"Este cupcake es de chocolate con crema\" o\n",
    "     > \"Este es de vainilla con fresas\".\n",
    "   * Solo **clasifica**.\n",
    "\n",
    "2. **Modelo generativo**\n",
    "\n",
    "   * Sería como un chef creativo que, después de ver muchas fotos, inventa nuevos diseños.\n",
    "\n",
    "     > \"Aquí tienes un cupcake que nunca has visto: mitad chocolate, mitad vainilla, con topping de frutilla azul\".\n",
    "   * **Crea algo nuevo** que sigue el estilo de los originales.\n",
    "\n",
    "---\n",
    "\n",
    "### Ejemplo en Python\n",
    "\n",
    "Vamos a simular un modelo generativo *ultra simplificado* para texto, para que los estudiantes vean la idea sin entrar en fórmulas todavía:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcee9f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Datos reales (ejemplos de cupcakes)\n",
    "sabores = [\"chocolate\", \"vainilla\", \"fresa\", \"limón\", \"café\"]\n",
    "toppings = [\"crema\", \"fresas\", \"chispas\", \"caramelo\", \"nueces\"]\n",
    "\n",
    "# \"Modelo generativo\" simple: mezcla aleatoria de lo aprendido\n",
    "def generar_cupcake():\n",
    "    sabor = random.choice(sabores)\n",
    "    topping = random.choice(toppings)\n",
    "    return f\"Cupcake de {sabor} con {topping}\"\n",
    "\n",
    "# Generar nuevos \"ejemplos\"\n",
    "for _ in range(5):\n",
    "    print(generar_cupcake())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c5e9f7",
   "metadata": {},
   "source": [
    "Este código no es un modelo real de IA, pero **ilustra la idea**:\n",
    "\n",
    "* Tenemos **datos originales** (sabores y toppings).\n",
    "* El “modelo” genera nuevas combinaciones.\n",
    "* Si tuviéramos un modelo real como una GAN o un Transformer, aprendería patrones complejos en lugar de mezclar aleatoriamente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f05781",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 2) GANs\n",
    "\n",
    "## 1. Arquitectura básica\n",
    "\n",
    "Una **GAN** (Red Generativa Antagónica - Generative Adversarial Network) es un sistema con **dos redes neuronales** que compiten y aprenden juntas:\n",
    "\n",
    "1. **Generador (G)**\n",
    "\n",
    "   * Entrada: un vector de **ruido aleatorio** $z$ (números sin sentido).\n",
    "   * Salida: un dato falso que intenta imitar un dato real (por ejemplo, una imagen).\n",
    "   * Objetivo: crear ejemplos tan realistas que el discriminador no pueda distinguirlos de los reales.\n",
    "\n",
    "2. **Discriminador (D)**\n",
    "\n",
    "   * Entrada: un dato (puede ser real o generado por G).\n",
    "   * Salida: probabilidad de que el dato sea real.\n",
    "   * Objetivo: identificar correctamente si la entrada es real o falsa.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Ejemplo empresarial: Industria de la moda\n",
    "\n",
    "**Contexto**\n",
    "Una marca de ropa quiere preparar la campaña de invierno, pero aún no ha fabricado las prendas. Necesita fotos de modelos usando la nueva ropa **antes** de que exista físicamente.\n",
    "\n",
    "**Cómo funciona**\n",
    "\n",
    "* **Generador (G)**: crea imágenes falsas de modelos usando ropa que aún no existe, basándose en bocetos y estilos anteriores.\n",
    "* **Discriminador (D)**: revisa esas imágenes y decide si parecen fotos reales de sesiones fotográficas anteriores o si son falsas.\n",
    "* Durante el entrenamiento, ambos mejoran:\n",
    "\n",
    "  * El generador hace imágenes cada vez más realistas.\n",
    "  * El discriminador se vuelve más exigente para detectar fallos.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Problemas comunes\n",
    "\n",
    "1. **Mode collapse**\n",
    "\n",
    "   * El generador produce pocas variantes (por ejemplo, siempre las mismas 2-3 combinaciones de ropa).\n",
    "   * En moda: si G solo genera fotos con una modelo y un vestido, sin variedad.\n",
    "\n",
    "2. **Inestabilidad en el entrenamiento**\n",
    "\n",
    "   * A veces G y D no aprenden al mismo ritmo y la GAN no converge.\n",
    "   * En moda: si el diseñador digital mejora demasiado rápido y D no puede detectarlo, o al revés.\n",
    "\n",
    "3. **Desequilibrio entre D y G**\n",
    "\n",
    "   * Si uno es mucho más fuerte, el otro deja de aprender.\n",
    "   * En moda: si el inspector detecta todo, el diseñador se frustra y no mejora.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Variantes y mejoras importantes\n",
    "\n",
    "1. **DCGAN** – Usa capas convolucionales y *Batch Normalization* para mejorar calidad de imágenes.\n",
    "   Ejemplo: genera fotos más detalladas de las prendas.\n",
    "\n",
    "2. **Wasserstein GAN (WGAN)** – Cambia la forma de medir la diferencia entre real y falso usando la **distancia de Wasserstein**; ayuda a entrenar más estable.\n",
    "\n",
    "3. **WGAN-GP** – Versión con penalización de gradiente (*gradient penalty*) para un entrenamiento aún más estable.\n",
    "\n",
    "4. **Conditional GAN (cGAN)** – Se entrena con etiquetas.\n",
    "   Ejemplo: “Genera una imagen de un abrigo rojo talla M” → El generador crea justo eso.\n",
    "\n",
    "5. **StyleGAN** – Arquitectura avanzada que genera imágenes de altísima calidad.\n",
    "   Ejemplo: fotos de modelos tan realistas que parecen hechas por un fotógrafo profesional.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Cómo medir la calidad de una GAN\n",
    "\n",
    "* **Inception Score (IS)** → Mide la calidad y diversidad de las imágenes.\n",
    "* **Fréchet Inception Distance (FID)** → Compara las características de imágenes reales y generadas; cuanto más bajo, mejor.\n",
    "\n",
    "\n",
    "## 6. Resumen visual del ejemplo empresarial\n",
    "\n",
    "| Elemento GAN      | Rol en empresa de moda                                        |\n",
    "| ----------------- | ------------------------------------------------------------- |\n",
    "| Generador (G)     | Diseñador digital que crea fotos falsas de la nueva colección |\n",
    "| Discriminador (D) | Equipo de control de calidad que detecta imágenes falsas      |\n",
    "| Ruido (z)         | Inspiración aleatoria del diseñador                           |\n",
    "| Entrenamiento     | Competencia entre diseñador e inspector                       |\n",
    "| Objetivo final    | Tener imágenes tan realistas que engañen incluso al cliente   |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223669b1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Ejercicio práctico: GAN simulada para generar tallas de ropa**\n",
    "\n",
    "**Objetivo:**\n",
    "Imitar el trabajo de una marca de moda que quiere generar tallas de ropa que parezcan reales, basándose en medidas anteriores.\n",
    "\n",
    "En vez de imágenes, trabajaremos con **números** (por ejemplo, medidas de pecho en cm). Así el código es más rápido y la idea queda clara.\n",
    "\n",
    "---\n",
    "\n",
    "### **Código paso a paso**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ef4209",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # libreria para calculos numéricos y uso de arreglos\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Datos reales (tallas reales de ropa)\n",
    "# -----------------------------\n",
    "# Generamos un conjunto de datos \"reales\" simulados: 1000 medidas (ej. cm de pecho)\n",
    "# np.random.normal(loc=95, scale=5, size=1000):\n",
    "#  - loc = media (95 cm)\n",
    "#  - scale = desviación estándar (5 cm)\n",
    "#  - size = número de muestras (1000)\n",
    "real_data = np.random.normal(loc=95, scale=5, size=1000)  # media ~95 cm, desviación ~5 cm\n",
    "\n",
    "# Nota: real_data es un arreglo numpy de forma (1000,). Podemos inspeccionar:\n",
    "#   np.mean(real_data), np.std(real_data)\n",
    "# para ver la media y desviación empíricas.\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Generador (G)\n",
    "# -----------------------------\n",
    "def generador(n):\n",
    "    \"\"\"\n",
    "    Genera 'n' tallas falsas (medidas de pecho) a partir de una entrada de ruido.\n",
    "    - Entrada:\n",
    "        n : int -> número de muestras que queremos generar\n",
    "    - Proceso:\n",
    "        ruido ~ N(0,1)  (distribución normal estándar)\n",
    "        salida = 80 + ruido * 5\n",
    "        Esto crea valores centrados alrededor de 80 (intencionalmente lejos de 95)\n",
    "        y con variabilidad proporcional a 5.\n",
    "    - Salida:\n",
    "        numpy.ndarray de tamaño n con valores simulados (floats).\n",
    "    \"\"\"\n",
    "    # ruido: vector de ruido aleatorio estándar\n",
    "    ruido = np.random.normal(0, 1, n)\n",
    "    # construimos las tallas \"falsas\" a partir del ruido\n",
    "    # empezamos con una media base de 80 (esto representa un generador \"malo\" al inicio)\n",
    "    return 80 + ruido * 5\n",
    "    # -> devuelve un array con forma (n,)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Discriminador (D)\n",
    "# -----------------------------\n",
    "def discriminador(x):\n",
    "    \"\"\"\n",
    "    Evalúa la 'probabilidad' de que x provenga de la distribución real.\n",
    "    Implementación:\n",
    "      - Calcula la media de los datos reales (media_real).\n",
    "      - Usa una función tipo núcleo gaussiano:\n",
    "            exp(- (x - media_real)^2 / (2 * sigma^2))\n",
    "        con sigma = 5.\n",
    "    Propiedades:\n",
    "      - Valor máximo = 1 si x == media_real.\n",
    "      - Los valores disminuyen al alejarse de la media real.\n",
    "      - Acepta x escalar o array (gracias a numpy broadcasting).\n",
    "    NOTA:\n",
    "      - Esto NO es una probabilidad calibrada por un clasificador entrenado,\n",
    "        es solo una función de similitud (kernel gaussiano) para fines didácticos.\n",
    "    \"\"\"\n",
    "    media_real = np.mean(real_data)  # referencia central (95 en la generación original)\n",
    "    sigma = 5.0 # estadistico utilizado para la desviacion estandar\n",
    "    # la expresión devuelve valores en (0,1], siendo 1 en la media real\n",
    "    return np.exp(-((x - media_real) ** 2) / (2 * sigma ** 2))\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Entrenamiento simulado\n",
    "# -----------------------------\n",
    "# Vamos a hacer 10 iteraciones (epochs) donde:\n",
    "#  - El generador produce algunas muestras.\n",
    "#  - El discriminador evalúa muestras reales y falsas.\n",
    "#  - Simulamos que el generador \"mejora\" moviendo sus salidas hacia la media real.\n",
    "for epoch in range(10):\n",
    "    # 1) el generador crea 5 tallas 'falsas'\n",
    "    falsas = generador(5)  # array de 5 valores, inicialmente alrededor de 80 +/- ruido\n",
    "\n",
    "    # 2) el discriminador evalúa 5 muestras reales muestreadas aleatoriamente\n",
    "    #    np.random.choice(real_data, 5) selecciona 5 valores del conjunto real\n",
    "    prob_reales = discriminador(np.random.choice(real_data, 5))\n",
    "    #    -> prob_reales es un array con 5 valores (cada uno ≤ 1)\n",
    "\n",
    "    # 3) el discriminador evalúa las tallas 'falsas' generadas\n",
    "    prob_falsas = discriminador(falsas)\n",
    "    #    -> valores pequeños si las falsas están lejos de la media real (95)\n",
    "\n",
    "    # 4) simulamos una 'mejora' del generador:\n",
    "    #    - mejora = promedio de la 'confianza' que el discriminador da a las falsas\n",
    "    #      Si prob_falsas es alto, significa que las falsas están más cerca de la realidad.\n",
    "    mejora = np.mean(prob_falsas)\n",
    "\n",
    "    #    - Actualizamos las tallas falsas acercándolas a 95 cm:\n",
    "    #      falsas = falsas + (95 - falsas) * mejora * 0.1\n",
    "    #      Desglose:\n",
    "    #        (95 - falsas)    -> vector de desplazamiento necesario para llegar a 95\n",
    "    #        * mejora          -> cuanto \"mérito\" tienen las falsas según el D\n",
    "    #        * 0.1             -> factor similar a una \"tasa de aprendizaje\" pequeña\n",
    "    #      Por tanto, movemos cada valor una fracción hacia 95 proporcional a mejora.\n",
    "    falsas = falsas + (95 - falsas) * mejora * 0.1  # se acercan a 95 cm de forma gradual\n",
    "\n",
    "    # Impresión para observar la evolución (redondeamos para que se vea limpio)\n",
    "    print(f\"Epoch {epoch+1}\")\n",
    "    print(f\"Tallas falsas generadas: {falsas.round(2)}\")\n",
    "    print(f\"Prob. de ser reales (falsas): {prob_falsas.round(2)}\")\n",
    "    print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863f1cc9",
   "metadata": {},
   "source": [
    "### **Palancas que pueden cambiar los resultados**\n",
    "\n",
    "- Acercar la media inicial del generador a 95 (por ejemplo 90 o 92). (Actual return 80 + ruido * 5)\n",
    "\n",
    "- Aumentar la tasa de ajuste (learning rate). Subirlo a 0.3–0.5 hace que las muestras se muevan más rápido hacia 95. (Actual - falsas = falsas + (95 - falsas) * mejora * 0.1)\n",
    "\n",
    "- Cambiar sigma en el discriminador ya que este controla cuán “tolerante” es el discriminador. Aumentarlo a 8 o a 10.\n",
    "\n",
    "- Aumentar número de epochs y tamaño de muestra\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4185472",
   "metadata": {},
   "source": [
    "### **Qué se aprenderá con este ejercicio**\n",
    "\n",
    "1. **Generador (G)**:\n",
    "\n",
    "   * Empieza generando valores alejados de los reales (ej. 80 cm).\n",
    "   * Aprende a acercarse a la media de las tallas reales (95 cm).\n",
    "\n",
    "2. **Discriminador (D)**:\n",
    "\n",
    "   * Juzga cada valor y da una probabilidad de que sea real.\n",
    "   * Si la talla está muy lejos de 95 cm, la probabilidad baja.\n",
    "\n",
    "3. **Competencia adversarial**:\n",
    "\n",
    "   * Si el discriminador detecta fácil las falsificaciones, el generador ajusta sus resultados.\n",
    "   * Poco a poco, las tallas falsas se parecen más a las reales.\n",
    "\n",
    "---\n",
    "\n",
    "**Explicación del ejemplo**\n",
    "\n",
    "* El **generador** es el diseñador digital que al principio crea tallas poco realistas (80 cm).\n",
    "* El **discriminador** es el departamento de control de calidad que detecta que esas tallas no corresponden a la colección real.\n",
    "* Con el tiempo, el diseñador ajusta y logra tallas que parecen de la colección oficial.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5445b946",
   "metadata": {},
   "source": [
    "# Ejercicio 1 - *Mini-DCGAN* con *Fashion-MNIST*\n",
    "\n",
    "## Caracteristicas:\n",
    "\n",
    "* Mini-DCGAN: Menos capas convolucionale, Menos parámetros, Entrenamiento más rápido y menos costoso en GPU/CPU.\n",
    "* Fashion-MNIST: dataset de imágenes en escala de grises (28×28) con 10 clases de ropa y calzado.\n",
    "\n",
    "## Objetivos de aprendizaje\n",
    "\n",
    "* Mostrar el flujo de una GAN (Generador ↔ Discriminador).\n",
    "* Ejecutar un entrenamiento rápido y visualizar cómo mejoran las imágenes.\n",
    "* Discutir problemas prácticos: mode collapse, inestabilidad, balance D/G.\n",
    "* Incluir buenas prácticas: seeds, checkpoints, logging, código modular.\n",
    "\n",
    "## Requisitos\n",
    "\n",
    "* Python 3.8+\n",
    "* PyTorch, torchvision, matplotlib\n",
    "\n",
    "```bash\n",
    "pip install torch torchvision matplotlib\n",
    "```\n",
    "\n",
    "* Ejecutar en CPU o preferiblemente GPU (si hay GPU disponible el entrenamiento será mucho más rápido).\n",
    "\n",
    "---\n",
    "\n",
    "## Explicación\n",
    "\n",
    "1. Cargar dataset Fashion-MNIST (28×28 grayscale).\n",
    "2. Generador: red totalmente conectada que transforma vector `z` → imagen 28×28.\n",
    "3. Discriminador: MLP que recibe imagen 28×28 y devuelve probabilidad real/falsa.\n",
    "4. Loop de entrenamiento clásico: actualizar D con reales+falsas, luego actualizar G intentando engañar a D.\n",
    "5. Mostrar imágenes generadas cada pocas épocas.\n",
    "\n",
    "---\n",
    "\n",
    "## Código\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f14eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Mini-DCGAN (en clase) - Fashion-MNIST\n",
    "Ejecuta rápido en CPU; si tienes GPU se acelerará.\n",
    "\"\"\"\n",
    "# -----------------------\n",
    "# 0) Importación de librerías necesarias\n",
    "# -----------------------\n",
    "import os                 # manejo de carpetas y rutas\n",
    "import random             # para control de aleatoriedad\n",
    "import torch              # librería principal de PyTorch (biblioteca de inteligencia artificial y deep learning)\n",
    "import torch.nn as nn     # para definir redes neuronales\n",
    "import torch.optim as optim  # optimizadores (Adam, SGD, etc.)\n",
    "from torchvision import datasets, transforms  # dataset y transformaciones\n",
    "from torch.utils.data import DataLoader        # para cargar datos por lotes\n",
    "from torchvision.utils import make_grid, save_image  # utilidades para imágenes\n",
    "import matplotlib.pyplot as plt                # para mostrar gráficos\n",
    "from datetime import datetime                  # para manejar tiempos (opcional)\n",
    "\n",
    "# -----------------------\n",
    "# 0) Configuración y reproducibilidad\n",
    "# -----------------------\n",
    "SEED = 42                         # semilla para resultados reproducibles\n",
    "random.seed(SEED)                 # semilla para librería random\n",
    "torch.manual_seed(SEED)           # semilla para PyTorch (CPU)\n",
    "if torch.cuda.is_available():     # si hay GPU disponible\n",
    "    torch.cuda.manual_seed_all(SEED)  # semilla para PyTorch (GPU)\n",
    "\n",
    "# Detectar si usamos GPU o CPU\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Carpeta donde se guardarán imágenes y modelos entrenados\n",
    "OUT_DIR = \"exercise1_outputs\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)  # crear carpeta si no existe\n",
    "\n",
    "# -----------------------\n",
    "# 1) Hiperparámetros\n",
    "# -----------------------\n",
    "BATCH_SIZE = 128      # tamaño del lote (imágenes procesadas a la vez)\n",
    "LATENT_DIM = 64       # tamaño del vector de ruido para el generador\n",
    "EPOCHS = 10           # número de veces que pasamos por el dataset\n",
    "LR = 2e-4             # tasa de aprendizaje (learning rate). Notación científica para el número 0.0002\n",
    "\n",
    "# -----------------------\n",
    "# 2) Dataset y transforms\n",
    "# -----------------------\n",
    "\n",
    "# Pipeline de transformaciones que se aplica a las imágenes antes de usarlas en un modelo de Deep Learning (en este caso  con PyTorch).\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),                     # Convierte una imagen (por ejemplo, en formato PIL o NumPy) a un tensor de PyTorch.\n",
    "    transforms.Normalize((0.5,), (0.5,))       # Ajusta los valores para que estén en el rango [-1, 1] en lugar de [0, 1] para entrenamiento rapido.\n",
    "])\n",
    "\n",
    "# Descargar y preparar dataset Fashion-MNIST\n",
    "\n",
    "\"\"\"\n",
    "Parámetros:\n",
    "\n",
    "root=\"./data\" → Carpeta donde se guardarán los datos. En este caso, la carpeta data en el directorio actual.\n",
    "train=True → Indica que quieres la parte de entrenamiento del dataset (hay otra parte para prueba train=False).\n",
    "download=True → Si no encuentra el dataset en la carpeta indicada, lo descarga automáticamente desde el servidor oficial de Zalando Research.\n",
    "transform=transform → Aplica las transformaciones que definiste antes (convertir a tensor y normalizar).\n",
    "\"\"\"\n",
    "\n",
    "dataset = datasets.FashionMNIST(\n",
    "    root=\"./data\", train=True, download=True, transform=transform\n",
    ")\n",
    "\n",
    "# DataLoader para manejar lotes y mezclar datos\n",
    "\n",
    "\"\"\"\n",
    "Parámetros:\n",
    "\n",
    "dataset: El conjunto de datos que quieres cargar, en este caso el que obtuviste con:\n",
    "\n",
    "batch_size=BATCH_SIZE: Tamaño del lote de datos que se entregará en cada iteración. Por ejemplo, si BATCH_SIZE = 64, cada vez que obtengas datos del loader recibirás 64 imágenes y 64 etiquetas. Esto afecta el uso de memoria y la velocidad de entrenamiento.\n",
    "\n",
    "shuffle=True: Mezcla aleatoriamente el orden de los datos en cada época de entrenamiento. Esto evita que el modelo aprenda patrones artificiales del orden de los datos.\n",
    "\n",
    "num_workers=2: Número de procesos en paralelo para cargar los datos. Más workers = carga más rápida, pero también más consumo de CPU. 0 significa que todo se carga en el proceso principal (más lento). En este caso, 2 procesos paralelos ayudan a leer las imágenes mientras la GPU entrena.\n",
    "\n",
    "pin_memory=True: Fija la memoria de los tensores en RAM de forma que la copia a la GPU sea más rápida. Esto solo tiene efecto si entrenas en GPU (cuda). Si estás en CPU, no aporta beneficio.\n",
    "\"\"\"\n",
    "\n",
    "loader = DataLoader(\n",
    "    dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "    num_workers=2, pin_memory=True\n",
    ")\n",
    "\n",
    "# -----------------------\n",
    "# 3) Modelos: Generator y Discriminator\n",
    "# -----------------------\n",
    "class Generator(nn.Module): # nn.Module: Bloque base de todas las redes neuronales en PyTorch.\n",
    "    def __init__(self, latent_dim=64): # Vector de entrada aleatorio (también llamado vector latente, latent vector) que se le pasa al Generador tendrá 64 valores.\n",
    "        super().__init__()\n",
    "        # Red totalmente conectada (MLP)\n",
    "        \n",
    "        # Definimos la red neuronal secuencial que actuará como generador\n",
    "        self.net = nn.Sequential(\n",
    "            # Capa totalmente conectada (FC) que recibe el vector latente (ruido) \n",
    "            # y lo expande a 256 neuronas.\n",
    "            nn.Linear(latent_dim, 256),\n",
    "            nn.ReLU(True),  # Función de activación ReLU para introducir no linealidad\n",
    "            \n",
    "            # Segunda capa FC: de 256 neuronas a 512 neuronas.\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            # Tercera capa FC: de 512 neuronas a 1024 neuronas.\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            # Capa de salida: de 1024 neuronas a 784 neuronas (28*28 píxeles).\n",
    "            nn.Linear(1024, 28*28),\n",
    "            \n",
    "            # Activación Tanh para que la salida esté en el rango [-1, 1],\n",
    "            # lo que es común cuando las imágenes están normalizadas en ese rango.\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    # Definimos el método forward, que describe cómo fluye la información\n",
    "    def forward(self, z):\n",
    "        # z: vector de ruido aleatorio (vector latente)\n",
    "        x = self.net(z)  # Pasamos el ruido por la red definida arriba\n",
    "    \n",
    "    # Reorganizamos el vector plano (784 valores) en una imagen\n",
    "    # con forma: batch_size × 1 canal × 28 alto × 28 ancho.\n",
    "        return x.view(-1, 1, 28, 28)\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()  # inicializa la clase base nn.Module\n",
    "\n",
    "        # Definición de la red neuronal del discriminador\n",
    "        self.net = nn.Sequential(  # Secuencia de capas\n",
    "            nn.Flatten(),                # Convierte la imagen 2D (1x28x28) en un vector de 784 elementos\n",
    "            nn.Linear(28*28, 512),        # Capa totalmente conectada: 784 -> 512 neuronas\n",
    "            nn.LeakyReLU(0.2, inplace=True),  # Activación LeakyReLU (mejor para GAN que ReLU pura)\n",
    "            \n",
    "            nn.Linear(512, 256),          # Otra capa densa: 512 -> 256\n",
    "            nn.LeakyReLU(0.2, inplace=True),  # Segunda activación LeakyReLU\n",
    "            \n",
    "            nn.Linear(256, 1),            # Capa de salida: 256 -> 1 neurona\n",
    "            nn.Sigmoid()                  # Convierte la salida a rango [0, 1], como probabilidad\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        # Pasa la imagen por la red\n",
    "        return self.net(img)  # Devuelve probabilidad de que sea real\n",
    "\n",
    "\n",
    "# Crear instancias de G y D\n",
    "G = Generator(LATENT_DIM).to(DEVICE)\n",
    "D = Discriminator().to(DEVICE)\n",
    "\n",
    "# -----------------------\n",
    "# 4) Loss, optimizadores e inicialización de pesos\n",
    "# -----------------------\n",
    "criterion = nn.BCELoss()  # Binary Cross-Entropy para clasificación real/falso\n",
    "opt_G = optim.Adam(G.parameters(), lr=LR, betas=(0.5, 0.999))  # optimizador de G\n",
    "opt_D = optim.Adam(D.parameters(), lr=LR, betas=(0.5, 0.999))  # optimizador de D\n",
    "\n",
    "# Inicialización recomendada para GANs\n",
    "def weights_init(m):\n",
    "    # m es un módulo de PyTorch (capa de la red)\n",
    "    if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.Linear)):\n",
    "        # Si la capa es una convolución (normal o transpuesta) o una capa densa (Linear)...\n",
    "        \n",
    "        # Inicializa los pesos con una distribución normal:\n",
    "        # media = 0.0, desviación estándar = 0.02\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "\n",
    "        # Si la capa tiene bias (sesgo), inicialízalo a 0\n",
    "        if getattr(m, \"bias\", None) is not None:\n",
    "            nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "# Aplicar inicialización\n",
    "G.apply(weights_init)\n",
    "D.apply(weights_init)\n",
    "\n",
    "# -----------------------\n",
    "# 5) Entrenamiento (loop)\n",
    "# -----------------------\n",
    "fixed_noise = torch.randn(36, LATENT_DIM, device=DEVICE)  # ruido fijo para ver evolución\n",
    "\n",
    "# -----------------------\n",
    "# Bucle de entrenamiento (comentado línea a línea)\n",
    "# -----------------------\n",
    "\n",
    "# ruido fijo para visualizar siempre las mismas muestras a lo largo de las epochs\n",
    "fixed_noise = torch.randn(36, LATENT_DIM, device=DEVICE)  # tensor (36, latent_dim) usado para generar ejemplos de referencia\n",
    "\n",
    "# iterar por cada época (1 .. EPOCHS)\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    # iterar por cada lote del DataLoader; imgs contiene las imágenes y _ ignora las etiquetas\n",
    "    for i, (imgs, _) in enumerate(loader):\n",
    "        imgs = imgs.to(DEVICE)                 # mover el lote de imágenes al dispositivo (CPU o GPU)\n",
    "        bs = imgs.size(0)                      # tamaño actual del lote (último lote puede ser menor que BATCH_SIZE)\n",
    "\n",
    "        # crear tensores de etiquetas:\n",
    "        # real_labels -> 1.0 (indicamos que estas son reales)\n",
    "        # fake_labels -> 0.0 (indicamos que estas son falsas)\n",
    "        real_labels = torch.ones(bs, 1, device=DEVICE)\n",
    "        fake_labels = torch.zeros(bs, 1, device=DEVICE)\n",
    "\n",
    "        # ------ Entrenar Discriminador ------\n",
    "        opt_D.zero_grad()                      # limpiar gradientes acumulados del discriminador\n",
    "\n",
    "        outputs_real = D(imgs)                 # pasar las imágenes reales por D -> salida entre 0 y 1\n",
    "        loss_real = criterion(outputs_real, real_labels)  # pérdida comparando con etiquetas reales (1)\n",
    "\n",
    "        noise = torch.randn(bs, LATENT_DIM, device=DEVICE)  # generar ruido aleatorio para crear falsas\n",
    "        fake_imgs = G(noise)                   # generar imágenes falsas con el generador\n",
    "\n",
    "        # IMPORTANT: .detach() evita que el gradiente fluya hacia G mientras actualizamos D\n",
    "        # así D se entrena con falsas \"estáticas\" y no afecta los parámetros de G en este paso\n",
    "        outputs_fake = D(fake_imgs.detach())   \n",
    "        loss_fake = criterion(outputs_fake, fake_labels)    # pérdida comparando con etiquetas falsas (0)\n",
    "\n",
    "        loss_D = loss_real + loss_fake         # pérdida total del discriminador (reales + falsas)\n",
    "        loss_D.backward()                      # backward: calcular gradientes de D\n",
    "        opt_D.step()                           # actualizar parámetros de D con el optimizador\n",
    "\n",
    "        # ------ Entrenar Generador ------\n",
    "        opt_G.zero_grad()                      # limpiar gradientes acumulados del generador\n",
    "\n",
    "        noise = torch.randn(bs, LATENT_DIM, device=DEVICE)  # generar nuevo ruido (puede ser el mismo o distinto)\n",
    "        fake_imgs = G(noise)                   # generar imágenes falsas (esta vez queremos actualizar G)\n",
    "\n",
    "        outputs = D(fake_imgs)                 # pasar las falsas por D (ahora sin detach: queremos que flujo llegue a G)\n",
    "        # objetivo del generador: engañar a D, por eso usamos 'real_labels' (1) como target\n",
    "        # si D clasifica las falsas como reales, la pérdida será baja\n",
    "        loss_G = criterion(outputs, real_labels)\n",
    "        loss_G.backward()                      # backward: calcular gradientes de G (a través de D)\n",
    "        opt_G.step()                           # actualizar parámetros de G\n",
    "\n",
    "        # Mostrar progreso cada 200 pasos (para seguimiento por consola)\n",
    "        if (i + 1) % 200 == 0:\n",
    "            # .item() extrae el valor escalar del tensor de pérdida para imprimirlo\n",
    "            print(f\"Epoch [{epoch}/{EPOCHS}] Step [{i+1}/{len(loader)}] \"\n",
    "                  f\"Loss_D: {loss_D.item():.4f} Loss_G: {loss_G.item():.4f}\")\n",
    "\n",
    "    # -----------------------\n",
    "    # Guardado de imágenes y checkpoints por epoch\n",
    "    # -----------------------\n",
    "    # Generar muestras con el ruido fijo para visualizar la evolución (no se calculan gradientes)\n",
    "    with torch.no_grad():\n",
    "        samples = G(fixed_noise).cpu()       # generar y mover a CPU para guardar/visualizar\n",
    "        # make_grid organiza las muestras en una cuadrícula; normalize=True reescala para visualizar\n",
    "        # value_range=(-1,1) indica el rango esperado de los píxeles (porque usamos Tanh y normalizamos)\n",
    "        grid = make_grid(samples, nrow=6, normalize=True, value_range=(-1, 1))\n",
    "        # guardar la cuadrícula como imagen PNG en la carpeta OUT_DIR\n",
    "        save_image(grid, os.path.join(OUT_DIR, f\"epoch_{epoch:02d}.png\"))\n",
    "\n",
    "    # Guardar los estados (pesos) de los modelos para poder recargar o continuar el entrenamiento\n",
    "    torch.save(G.state_dict(), os.path.join(OUT_DIR, f\"G_epoch_{epoch}.pth\"))  # pesos del generador\n",
    "    torch.save(D.state_dict(), os.path.join(OUT_DIR, f\"D_epoch_{epoch}.pth\"))  # pesos del discriminador\n",
    "\n",
    "# Mensaje final al terminar todo el entrenamiento\n",
    "print(\"Entrenamiento finalizado. Imágenes y checkpoints en:\", OUT_DIR)\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# 6) Mostrar última cuadrícula en pantalla\n",
    "# -----------------------\n",
    "img = plt.imread(os.path.join(OUT_DIR, f\"epoch_{EPOCHS:02d}.png\"))\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.title(f\"Samples after epoch {EPOCHS}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b74fac2",
   "metadata": {},
   "source": [
    "### Posibles comportamientos:\n",
    "\n",
    "Aquí cada línea muestra:\n",
    "\n",
    "* Epoch [x/10] → Época actual de entrenamiento, de un total de 10.\n",
    "* Step [y/469] → Paso actual dentro de la época (469 lotes en total).\n",
    "* Loss_D → Loss (error) del Discriminador.\n",
    "* Loss_G → Loss (error) del Generador.\n",
    "\n",
    "Interpretación rápida:\n",
    "\n",
    "* Loss_D alto → el discriminador se confunde (o el generador mejora).\n",
    "\n",
    "* Loss_G alto → el generador tiene problemas para engañar al discriminador.\n",
    "\n",
    "* Idealmente, ambos valores oscilan y se equilibran, sin que uno domine completamente.\n",
    "\n",
    "Comportamiento que se podría observar:\n",
    "\n",
    "* Si el **Loss_G** va subiendo es porque el generador intenta aprender.\n",
    "* Si durrante el entrenamiento **Loss_D** supera 1.0 → el discriminador está ganando y el generador pierde capacidad.\n",
    "* Evaluar ajustar tasas de aprendizaje o usar técnicas de estabilización como label smoothing o batch normalization.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61650bfd",
   "metadata": {},
   "source": [
    "## Resultado esperado\n",
    "\n",
    "* Durante la demo verás imágenes que pasan de ruido a formas que recuerdan dígitos/prendas.\n",
    "* Muestra los archivos `exercise1_outputs/epoch_*.png` y explica la evolución.\n",
    "\n",
    "## Puntos de discusión / talking points\n",
    "\n",
    "* ¿Qué pasa si aumentamos `EPOCHS` a 50? (mejor calidad, pero más tiempo)\n",
    "* ¿Qué es `latent_dim` y cómo cambia las muestras?\n",
    "* ¿Por qué usamos `Tanh()` y normalizamos a `[-1,1]`?\n",
    "* Señalar problemas: pérdida oscilante no siempre indica mala calidad visual.\n",
    "\n",
    "## Checklist de calidad (mínimo en la demo)\n",
    "\n",
    "* Uso de seed y reproducibilidad básica.\n",
    "* Guardado de checkpoints.\n",
    "* Comentarios en el código (ya incluidos).\n",
    "* Explicar seguridad y privacidad: no usar datos con PII sin consentimiento.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9557cc9",
   "metadata": {},
   "source": [
    "# Ejercicio 2 —  cGAN sencillo sobre *Fashion-MNIST* (condicionar por tipo de prenda)\n",
    "\n",
    "**Objetivo:** \n",
    "\n",
    "Implementar y entender cómo generar imágenes condicionadas por etiqueta (p. ej. “abrigo”, “zapato”, “camisa”). Este ejercicio es más completo, incluye tareas adicionales, métricas y criterios de entrega.\n",
    "\n",
    "## Aprendizajes esperados\n",
    "\n",
    "* Implementar un **Conditional GAN** (cGAN).\n",
    "* Entender cómo incorporar etiquetas en G y D (embedding + concatenación).\n",
    "* Generar imágenes específicas por label y evaluar visualmente la calidad y la diversidad.\n",
    "* Aplicar buenas prácticas de ingeniería: reproducibilidad, guardado de checkpoints, README, tests básicos.\n",
    "\n",
    "---\n",
    "\n",
    "## Descripción del problema\n",
    "\n",
    "La empresa “FashionNow” quiere generar imágenes de prendas **específicas** sin fabricarlas. Se te pide crear un **cGAN** que, dado un label (0–9 en Fashion-MNIST), genere una imagen correspondiente a ese tipo de prenda.\n",
    "\n",
    "**Entradas:** etiqueta `y` (int 0..9), ruido `z`.\n",
    "**Salida:** imagen 28×28 condicionada en `y`.\n",
    "\n",
    "**Entregables mínimos:**\n",
    "\n",
    "1. Código `cgan_fashion.py` entrenable con `python cgan_fashion.py`.\n",
    "2. Carpeta `outputs/` con muestras por clase (al menos 10 imágenes por clase).\n",
    "3. Checkpoints de G y D.\n",
    "4. `README.md` con instrucciones, parámetros y resultados.\n",
    "5. Informe (1–2 páginas) con observaciones: problemas detectados y cómo los resolvieron.\n",
    "\n",
    "---\n",
    "\n",
    "## Código (completo y comentado)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6390e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "cGAN sobre Fashion-MNIST (tarea de estudiantes)\n",
    "Estructura:\n",
    " - Generator recibe (z, label) y genera imagen condicionada.\n",
    " - Discriminator recibe (img, label) y predice real/falso considerando label.\n",
    "\"\"\"\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "from datetime import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image, make_grid\n",
    "\n",
    "# -----------------------\n",
    "# Config / reproducibilidad\n",
    "# -----------------------\n",
    "SEED = 123\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "OUT_DIR = \"exercise2_outputs\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# -----------------------\n",
    "# Hiperparámetros (ajustables)\n",
    "# -----------------------\n",
    "BATCH_SIZE = 128\n",
    "LATENT_DIM = 100\n",
    "EPOCHS = 25\n",
    "LR = 2e-4\n",
    "NUM_CLASSES = 10\n",
    "EMBED_DIM = 50   # embedding para la etiqueta\n",
    "\n",
    "# -----------------------\n",
    "# Dataset\n",
    "# -----------------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "dataset = datasets.FashionMNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "\n",
    "# -----------------------\n",
    "# Modelos: Generator y Discriminator condicionados\n",
    "# -----------------------\n",
    "class CGANGenerator(nn.Module):\n",
    "    def __init__(self, latent_dim, num_classes, embed_dim):\n",
    "        super().__init__()\n",
    "        # embedding para la etiqueta\n",
    "        self.label_emb = nn.Embedding(num_classes, embed_dim)\n",
    "        # concatenamos z (latent_dim) + embedding (embed_dim)\n",
    "        input_dim = latent_dim + embed_dim\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(1024, 28*28),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, noise, labels):\n",
    "        # labels: tensor (batch,)\n",
    "        lbl_emb = self.label_emb(labels)                # (batch, embed_dim)\n",
    "        x = torch.cat([noise, lbl_emb], dim=1)          # (batch, latent+embed)\n",
    "        out = self.net(x)\n",
    "        return out.view(-1, 1, 28, 28)\n",
    "\n",
    "class CGANDiscriminator(nn.Module):\n",
    "    def __init__(self, num_classes, embed_dim):\n",
    "        super().__init__()\n",
    "        # label embedding para concatenar con imagen (a la entrada)\n",
    "        self.label_emb = nn.Embedding(num_classes, embed_dim)\n",
    "        # imagen 28*28 + label emb\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(28*28 + embed_dim, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, img, labels):\n",
    "        lbl_emb = self.label_emb(labels)\n",
    "        img_flat = img.view(img.size(0), -1)\n",
    "        x = torch.cat([img_flat, lbl_emb], dim=1)\n",
    "        return self.net(x)\n",
    "\n",
    "# Inicializar\n",
    "G = CGANGenerator(LATENT_DIM, NUM_CLASSES, EMBED_DIM).to(DEVICE)\n",
    "D = CGANDiscriminator(NUM_CLASSES, EMBED_DIM).to(DEVICE)\n",
    "\n",
    "# Inicialización de pesos (normal)\n",
    "def weights_init(m):\n",
    "    if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.Linear)):\n",
    "        nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "        if getattr(m, \"bias\", None) is not None:\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "G.apply(weights_init)\n",
    "D.apply(weights_init)\n",
    "\n",
    "# -----------------------\n",
    "# Pérdida y optimizadores\n",
    "# -----------------------\n",
    "criterion = nn.BCELoss()\n",
    "opt_G = optim.Adam(G.parameters(), lr=LR, betas=(0.5, 0.999))\n",
    "opt_D = optim.Adam(D.parameters(), lr=LR, betas=(0.5, 0.999))\n",
    "\n",
    "# -----------------------\n",
    "# Helpers: guardado de muestras condicionadas\n",
    "# -----------------------\n",
    "def sample_by_class(epoch, num_samples_per_class=10):\n",
    "    \"\"\"\n",
    "    Genera imágenes condicionadas para cada clase y las guarda en outputs.\n",
    "    \"\"\"\n",
    "    G.eval()\n",
    "    imgs_all = []\n",
    "    labels_all = []\n",
    "    with torch.no_grad():\n",
    "        for cls in range(NUM_CLASSES):\n",
    "            z = torch.randn(num_samples_per_class, LATENT_DIM, device=DEVICE)\n",
    "            labels = torch.full((num_samples_per_class,), cls, dtype=torch.long, device=DEVICE)\n",
    "            gen_imgs = G(z, labels)  # (num_samples_per_class, 1, 28, 28)\n",
    "            imgs_all.append(gen_imgs)\n",
    "            labels_all += [cls] * num_samples_per_class\n",
    "    imgs_all = torch.cat(imgs_all, dim=0)\n",
    "    grid = make_grid(imgs_all.cpu(), nrow=num_samples_per_class, normalize=True, value_range=(-1,1))\n",
    "    save_image(grid, os.path.join(OUT_DIR, f\"sample_by_class_epoch_{epoch}.png\"))\n",
    "    G.train()\n",
    "\n",
    "# -----------------------\n",
    "#  Loop de entrenamiento\n",
    "# -----------------------\n",
    "fixed_noise = torch.randn(100, LATENT_DIM, device=DEVICE)  # para visualizar aleatorio\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    for i, (imgs, labels) in enumerate(loader):\n",
    "        imgs = imgs.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        bs = imgs.size(0)\n",
    "\n",
    "        real = torch.ones(bs, 1, device=DEVICE)\n",
    "        fake = torch.zeros(bs, 1, device=DEVICE)\n",
    "\n",
    "        # --- Entrenar Discriminador ---\n",
    "        opt_D.zero_grad()\n",
    "        # Reales con sus labels\n",
    "        out_real = D(imgs, labels)\n",
    "        loss_real = criterion(out_real, real)\n",
    "\n",
    "        # Falsos con labels correspondientes (sample de ruido)\n",
    "        z = torch.randn(bs, LATENT_DIM, device=DEVICE)\n",
    "        gen_labels = torch.randint(0, NUM_CLASSES, (bs,), device=DEVICE)\n",
    "        gen_imgs = G(z, gen_labels)\n",
    "        out_fake = D(gen_imgs.detach(), gen_labels)\n",
    "        loss_fake = criterion(out_fake, fake)\n",
    "\n",
    "        loss_D = (loss_real + loss_fake) / 2\n",
    "        loss_D.backward()\n",
    "        opt_D.step()\n",
    "\n",
    "        # --- Entrenar Generador ---\n",
    "        opt_G.zero_grad()\n",
    "        z2 = torch.randn(bs, LATENT_DIM, device=DEVICE)\n",
    "        target_labels = torch.randint(0, NUM_CLASSES, (bs,), device=DEVICE)  # queremos generar para labels aleatorios\n",
    "        gen_imgs2 = G(z2, target_labels)\n",
    "        out_gen = D(gen_imgs2, target_labels)\n",
    "        loss_G = criterion(out_gen, real)  # queremos que D clasifique como real\n",
    "        loss_G.backward()\n",
    "        opt_G.step()\n",
    "\n",
    "        if (i+1) % 200 == 0:\n",
    "            print(f\"Epoch [{epoch}/{EPOCHS}] Step [{i+1}/{len(loader)}] Loss_D: {loss_D.item():.4f} Loss_G: {loss_G.item():.4f}\")\n",
    "\n",
    "    # Guardar muestras por clase cada 1-2 epochs\n",
    "    sample_by_class(epoch)\n",
    "\n",
    "    # Guardar checkpoints\n",
    "    torch.save(G.state_dict(), os.path.join(OUT_DIR, f\"G_epoch_{epoch}.pth\"))\n",
    "    torch.save(D.state_dict(), os.path.join(OUT_DIR, f\"D_epoch_{epoch}.pth\"))\n",
    "\n",
    "print(\"Entrenamiento finalizado. Revisa la carpeta:\", OUT_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a916bed",
   "metadata": {},
   "source": [
    "## Consejos y soluciones a problemas comunes\n",
    "\n",
    "* **Mode collapse**: intentar disminuir LR del generador, usar label smoothing, añadir ruido a etiquetas, usar WGAN-GP.\n",
    "* **D aprende demasiado rápido**: reducir pasos de entrenamiento de D (o lr\\_D < lr\\_G).\n",
    "* **Pérdidas oscilantes**: comprobar visualmente las imágenes; las pérdidas no siempre reflejan calidad visual.\n",
    "* **Sin GPU**: reducir `EPOCHS`, `BATCH_SIZE` o entrenar con subset del dataset (por ejemplo 10k imágenes).\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
